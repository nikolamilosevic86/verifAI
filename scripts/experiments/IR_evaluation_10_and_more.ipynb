{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine BioASQ with Our IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "from opensearchpy import OpenSearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened...\n"
     ]
    }
   ],
   "source": [
    "host = '3.23.103.76' #host = 'localhost' \n",
    "port = 9200\n",
    "auth =('admin','IVIngi2024!') #auth = ('admin','admin') \n",
    "client_lexical = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    "    timeout=500, \n",
    "    max_retries=1\n",
    "    #connection_class=RequestsHttpConnection \n",
    "#    http_compress = True, # enables gzip compression for request bodies\n",
    "#    use_ssl = False,\n",
    "#   verify_certs = False,\n",
    "#    ssl_assert_hostname = False,\n",
    "#    ssl_show_warn = False\n",
    ")\n",
    "print(\"Connection opened...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 1, 'timed_out': False, '_shards': {'total': 4, 'successful': 4, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 1, 'relation': 'eq'}, 'max_score': 15.348576, 'hits': [{'_index': 'medline-faiss-hnsw-lexical', '_id': '2289988', '_score': 15.348576, '_source': {'text': 'The role of ret gene in the pathogenesis of Hirschsprung disease. Hirschsprung disease is a congenital disorder with the incidence of 1 per 5000 live births, characterized by the absence of intestinal ganglion cells. In the etiology of Hirschsprung disease various genes play a role; these are: RET, EDNRB, GDNF, EDN3 and SOX10, NTN3, ECE1, Mutations in these genes may result in dominant, recessive or multifactorial patterns of inheritance. Diverse models of inheritance, co-existence of numerous genetic disorders and detection of numerous chromosomal aberrations together with involvement of various genes confirm the genetic heterogeneity of Hirschsprung disease. Hirschsprung disease might well serve as a model for many complex disorders in which the search for responsible genes has only just been initiated. It seems that the most important role in its genetic etiology plays the RET gene, which is involved in the etiology of at least four diseases. This review focuses on recent advances of the importance of RET gene in the etiology of Hirschsprung disease.'}}]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_text={\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"pmid\": \"15858239\"\n",
    "    }\n",
    "  },\n",
    "  \"_source\": [\"text\"]  \n",
    "}\n",
    "\n",
    "# Execute the query\n",
    "response = client_lexical.search(\n",
    "    index=\"medline-faiss-hnsw-lexical\",\n",
    "    body=query_text\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for generarive component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get text from our IR for given pmid\n",
    "\n",
    "def get_document_text(pmid, client):\n",
    "    # Format the query text with the correct PubMed ID\n",
    "    query_text = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"pmid\": pmid\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"text\"]\n",
    "    }\n",
    "\n",
    "    # Use the provided OpenSearch client to execute the query\n",
    "    response = client.search(\n",
    "        index=\"medline-faiss-hnsw-lexical\",\n",
    "        body=query_text\n",
    "    )\n",
    "\n",
    "    # Check if the response has hits and return the text\n",
    "    if response['hits']['hits']:\n",
    "        # Assuming that the first hit contains the relevant document\n",
    "        return response['hits']['hits'][0]['_source']['text']\n",
    "    else:\n",
    "        # Return a default message or handle as needed\n",
    "        return \"No document found for PMID: {}\".format(pmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leigh Syndrome Mimicking Wernicke's Encephalopathy: A Case Report. Leigh syndrome or subacute necrotizing encephalomyelopathy is a rare, rapidly progressive neurodegenerative disorder. In general, symptoms such as shortness of breath and decreased cardiac function usually occur within 1 year of life. It is a serious disease with a mortality rate of 75% in 2-3 years. The cause of Leigh syndrome is DNA mutation. Approximately 75% of patients have nuclear DNA mutations while 25% have mitochondrial DNA mutations. Clinical symptoms vary depending on the affected brain area. Neuroimaging plays an important role in diagnosing patients with Leigh syndrome. Late-onset Leigh syndrome is rarer and progresses more slowly compared to the classic form. Here, we report a case of late-onset Leigh's syndrome mimicking Wernicke's encephalopathy.\n"
     ]
    }
   ],
   "source": [
    "#checking one example\n",
    "pmid = \"36237717\"  # Example PubMed ID\n",
    "document_text = get_document_text(pmid, client_lexical)\n",
    "print(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_structure = {\n",
    "    \"questions\": [\n",
    "        {\n",
    "            \"question\": \"Question here\",\n",
    "            \"type\": \"summary\",\n",
    "            \"exact_answer\": [\"Exact answer here\"],\n",
    "            \"ideal_answer\": \"Ideal answer here\",\n",
    "            \"abstracts\": []\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def populate_abstracts(question, pmids, client):\n",
    "   \n",
    "    #Populate the 'abstracts' field for a given question with texts fetched using PubMed IDs. \n",
    "    #Args:\n",
    "    #question (dict): The question dictionary to populate.\n",
    "    #pmids (list of str): List of PubMed IDs.\n",
    "    #client (OpenSearchClient): The OpenSearch client instance.\n",
    "   \n",
    "    # Clear existing abstracts (if this function is to be reused)\n",
    "    question['abstracts'] = []\n",
    "\n",
    "    for pmid in tqdm(pmids, desc=\"Fetching texts\", leave=False):\n",
    "        text = get_document_text(pmid, client)\n",
    "        question['abstracts'].append({\n",
    "            \"id\": pmid,\n",
    "            \"text\": text\n",
    "        })\n",
    "\"\"\"\n",
    "def populate_abstracts(question, pmids, client):\n",
    "    # Initialize the list with None to reserve order\n",
    "    abstracts = [None] * len(pmids)\n",
    "\n",
    "    # Using tqdm to show progress for fetching document texts\n",
    "    for index, pmid in enumerate(tqdm(pmids, desc=\"Fetching texts\", leave=False)):\n",
    "        text = get_document_text(pmid, client)\n",
    "        abstracts[index] = {\n",
    "            \"id\": pmid,\n",
    "            \"text\": text\n",
    "        }\n",
    "\n",
    "    # Filter out None values in case any text could not be fetched\n",
    "    question['abstracts'] = [abstract for abstract in abstracts if abstract]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "#evaluation_file = 'training12b_new.json'\n",
    "#with open(evaluation_file, 'r') as f:\n",
    " #   data = json.load(f)\n",
    "\n",
    "#print(len(data['questions']))\n",
    "BioASQ_filepath = 'training12b_new.json'\n",
    "#BioASQ_filepath = 'BioASQ_small.json'\n",
    "def read_bioasq_file(filepath):\n",
    "    \"\"\"\n",
    "    Read the BioASQ JSON file.\n",
    "    \n",
    "    Args:\n",
    "    filepath (str): The path to the BioASQ file.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of questions from the BioASQ file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        bioasq_data = json.load(file)\n",
    "    return bioasq_data['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_custom_json_structure(bioasq_questions, client):\n",
    "    \"\"\"\n",
    "    Create a custom JSON structure based on BioASQ data.\n",
    "    \n",
    "    Args:\n",
    "    bioasq_questions (list): List of questions from BioASQ data.\n",
    "    client (OpenSearchClient): The OpenSearch client instance.\n",
    "    \n",
    "    Returns:\n",
    "    dict: The custom JSON structure populated with abstracts.\n",
    "    \"\"\"\n",
    "    json_structure = {\"questions\": []}\n",
    "\n",
    "    for question in tqdm(bioasq_questions, desc=\"Processing questions\"):\n",
    "        # Create a new question entry\n",
    "        new_question = {\n",
    "            \"id\": question.get(\"id\", \"No ID\"), \n",
    "            \"question\": question.get(\"body\", \"No question body\"),\n",
    "            \"type\": question.get(\"type\", \"\"),\n",
    "            \"exact_answer\": question.get(\"exact_answer\", []),\n",
    "            \"ideal_answer\": question.get(\"ideal_answer\", \"No ideal answer\"),\n",
    "            \"abstracts\": []\n",
    "        }\n",
    "\n",
    "        # Extract PubMed IDs from the 'documents' URLs\n",
    "        pmids = [doc.split('/')[-1] for doc in question.get('documents', [])]\n",
    "        \n",
    "        # Populate abstracts\n",
    "        populate_abstracts(new_question, pmids, client)\n",
    "        \n",
    "        # Add the populated question to the json structure\n",
    "        json_structure['questions'].append(new_question)\n",
    "\n",
    "    return json_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom BioASQ-ALL - with abstract's text from our IR for pmid from bioASQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions: 100%|██████████| 5049/5049 [1:53:49<00:00,  1.35s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create the custom JSON: 6829.41 seconds\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "#bioasq_filepath = 'path_to_your_BioAsq.json'  # Set the path to your BioASQ file\n",
    "start_time = time.time()\n",
    "\n",
    "bioasq_questions = read_bioasq_file(BioASQ_filepath)\n",
    "custom_json = create_custom_json_structure(bioasq_questions, client_lexical)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "# Save the new JSON structure to a file\n",
    "with open('custom_bioasq_output_ALL.json', 'w') as outfile:\n",
    "    json.dump(custom_json, outfile, indent=4)\n",
    "\n",
    "print(f\"Time taken to create the custom JSON: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create json file for BioASQ questions with our retrieval results - for 5 BioASW question with 5 or more abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom BioASQ with only one unique Ideal answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data has been saved to custom_bioasq_output_One_ideal.json\n",
      "The number of question with one Ideal answer 3634\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_ideal_answers(input_filepath, output_filepath):\n",
    "    # Load the data from the input JSON file\n",
    "    with open(input_filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    processed_questions = []\n",
    "\n",
    "    for question in data['questions']:\n",
    "        ideal_answers = question['ideal_answer']\n",
    "\n",
    "        # Check if there's more than one ideal answer\n",
    "        if isinstance(ideal_answers, list) and len(ideal_answers) > 1:\n",
    "            # Use a set to identify unique answers\n",
    "            unique_answers = set(ideal_answers)\n",
    "\n",
    "            if len(unique_answers) == 1:\n",
    "                # If all ideal answers are the same, keep one\n",
    "                question['ideal_answer'] = unique_answers.pop()\n",
    "            else:\n",
    "                # If there are different ideal answers, skip this question\n",
    "                continue\n",
    "        # If there's only one ideal answer, or it has been processed to one, add to processed questions\n",
    "        processed_questions.append(question)\n",
    "\n",
    "    # Prepare the final structure with processed questions\n",
    "    final_data = {'questions': processed_questions}\n",
    "\n",
    "    # Save the processed data to a new JSON file\n",
    "    with open(output_filepath, 'w') as outfile:\n",
    "        json.dump(final_data, outfile, indent=4)\n",
    "\n",
    "    print(f\"Processed data has been saved to {output_filepath}\")\n",
    "    print(\"The number of question with one Ideal answer\", len(processed_questions))\n",
    "\n",
    "# Define file paths\n",
    "input_filepath = 'custom_bioasq_output_ALL.json'\n",
    "output_filepath = 'custom_bioasq_output_One_ideal.json'\n",
    "\n",
    "# Process the file\n",
    "process_ideal_answers(input_filepath, output_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Kraj pripreme podataka za generativnu komponentu</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create subseto of BioASQ - question with 10 or more relevant abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to BioASQ_10_or_more.json\n",
      "Number od questions with 10 or more abstracts: 1787\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_questions_with_ten_or_more_documents(input_filepath, output_filepath):\n",
    "    # Load the data from the BioASQ JSON file\n",
    "    with open(input_filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    filtered_questions = []\n",
    "\n",
    "    # Filter questions based on the number of documents\n",
    "    for question in data['questions']:\n",
    "        # Check if there are 10 or more documents\n",
    "        if len(question['documents']) >= 10:\n",
    "            filtered_questions.append(question)\n",
    "\n",
    "    # Prepare the final structure with filtered questions\n",
    "    final_data = {'questions': filtered_questions}\n",
    "    # Save the filtered data to a new JSON file\n",
    "    with open(output_filepath, 'w') as outfile:\n",
    "        json.dump(final_data, outfile, indent=4)\n",
    "\n",
    "    print(f\"Filtered data has been saved to {output_filepath}\")\n",
    "    print(\"Number od questions with 10 or more abstracts:\", len(filtered_questions))\n",
    "# Define file paths\n",
    "input_filepath = 'training12b_new.json'  # Set the correct path to your BioASQ file\n",
    "output_filepath = 'BioASQ_10_or_more.json'\n",
    "\n",
    "# Process the file\n",
    "filter_questions_with_ten_or_more_documents(input_filepath, output_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from qdrant_client.http.models import PointStruct\n",
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "# 3.145.52.195\n",
    "#client_semantic = QdrantClient(host, port=6333, timeout = 60)\n",
    "\n",
    "verifai_ip='3.23.103.76'\n",
    "qdrant_port=6333\n",
    "TIMEOUT=60\n",
    "url = f\"https://{verifai_ip}:{qdrant_port}\"\n",
    "qdrant_api=\"8da7725d78141e19a9bf3d878f4cb333fedb56eed9727904b46ce4b32e1ce085\"\n",
    "client_semantic = QdrantClient(url=url, api_key=qdrant_api, timeout=TIMEOUT, https=True,**{'verify': False})\n",
    "#client_semantic = QdrantClient(host, port=6333, timeout = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the type of lexical indexing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_pmid = False\n",
    "\n",
    "if lexical_pmid:\n",
    "    index_name_lexical = 'medline-faiss-hnsw-lexical-pmid'\n",
    "else:\n",
    "    index_name_lexical ='medline-faiss-hnsw-lexical'\n",
    "\n",
    "coll_name_semantic = \"medline-faiss-hnsw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "model_card = 'sentence-transformers/msmarco-distilbert-base-tas-b'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Ensure that the necessary NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, index_lexical:str = \"medline-faiss-hnsw-lexical\",lexical_pmid = False, index_name_semantic =\"medline-faiss-hnsw\", rescore = False, model=None, lexical_client=None, semantic_client=None, output_file_path=\"queries/queries.tsv\", stopwords=set([])):\n",
    "        self.index_lexical_name = index_lexical\n",
    "        self.index_name_semantic = index_name_semantic\n",
    "        # 2 index name (?)\n",
    "        self.model = model\n",
    "        #self.lexical_pmid = lexical_pmid\n",
    "        self.lexical_client = lexical_client\n",
    "        self.semantic_client = semantic_client\n",
    "        self.output_file_path = output_file_path\n",
    "        self.stop_words = stopwords\n",
    "        self.query_result = []\n",
    "        self.rescore = rescore\n",
    "        self.lexical_query = self.lexical_query_pmid if lexical_pmid else self.lexical_query\n",
    "    \n",
    "    def set_rescore(self, rescore):\n",
    "        self.rescore = rescore\n",
    "\n",
    "    def preprocess_query(self, query_str):\n",
    "        return ' '.join([word for word in word_tokenize(query_str) if word.lower() not in self.stop_words])\n",
    "\n",
    "    def save_results(self):\n",
    "        with open(self.output_file_path, \"w\") as file:\n",
    "            json.dump(self.query_result, file, indent=4)\n",
    "      \n",
    "    \n",
    "    def reorder_pmid(self, retrived_documents):\n",
    "        pmid_scores = {}\n",
    "        \n",
    "        # Iterate through the set data\n",
    "        for _, value in retrived_documents.items():\n",
    "            pmid = value['pmid']\n",
    "            score = value['score']\n",
    "            \n",
    "            # Check if pmid already exists in the dictionary\n",
    "            if pmid in pmid_scores:\n",
    "                pmid_scores[pmid] += score\n",
    "            else:\n",
    "                pmid_scores[pmid] = score\n",
    "           \n",
    "        return pmid_scores\n",
    "    \n",
    "    def lexical_query(self, query_str, limit=10):\n",
    "        if self.lexical_client == None:\n",
    "            raise ValueError(\"No Lexical client defined\")\n",
    "        \n",
    "        query = {\n",
    "                \"size\": limit,\n",
    "                \"query\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query_str,\n",
    "                        \"fields\": [\"text\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "       \n",
    "        results = self.lexical_client.search(index=self.index_lexical_name, body=query) \n",
    "        retrived_documents = {}\n",
    "        max_score = results['hits']['max_score']\n",
    "     \n",
    "        for hit in results[\"hits\"][\"hits\"]:\n",
    "            \n",
    "            pmid = hit[\"_source\"][\"pmid\"]\n",
    "            score = hit[\"_score\"]\n",
    "            auto_id = hit[\"_id\"]\n",
    "            \n",
    "            \n",
    "            \n",
    "            retrived_documents[auto_id] = {\n",
    "                \"score\": round(score/max_score, 5),\n",
    "                \"pmid\": pmid\n",
    "                }\n",
    "        \n",
    "        retrived_documents = self.reorder_pmid(retrived_documents)\n",
    "        return retrived_documents #adjust the return \n",
    "    \n",
    "    def lexical_query_pmid(self, query_str, limit=10):\n",
    "        #print(\"Lexical = \",query_str)\n",
    "        if self.lexical_client == None:\n",
    "            raise ValueError(\"No Lexical client defined\")\n",
    "        \n",
    "        query = {\n",
    "                \"size\": limit,\n",
    "                \"query\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query_str,\n",
    "                        \"fields\": [\"full_text\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        results = self.lexical_client.search(index=self.index_lexical_name, body=query) \n",
    "        \n",
    "        retrieved_documents = {}\n",
    "        max_score = results['hits']['max_score']\n",
    "        for hit in results[\"hits\"][\"hits\"]:\n",
    "            \n",
    "            pmid = hit[\"_source\"][\"pmid\"]\n",
    "            score = hit[\"_score\"] / max_score\n",
    "            \n",
    "            retrieved_documents[pmid] = score\n",
    "            \n",
    "        return retrieved_documents #adjust the return \n",
    "\n",
    "    def semantic_query(self, query, limit=10):\n",
    "        #print(\"semantic = \",query)\n",
    "        if self.semantic_client == None:\n",
    "            raise ValueError(\"No Semantic client defined\")\n",
    "        if self.model == None:\n",
    "            raise ValueError(\"No model defined\")\n",
    "        \n",
    "        query_vector = self.model.encode(query).tolist()\n",
    "    \n",
    "        search_params=models.SearchParams(\n",
    "            quantization=models.QuantizationSearchParams(rescore=self.rescore)\n",
    "            )\n",
    "        results = self.semantic_client.search(collection_name=self.index_name_semantic,query_vector=query_vector,search_params=search_params, limit=limit)\n",
    "    \n",
    "        #results = self.semantic_client.search(collection_name=self.index_name_semantic,query_vector=query_vector, limit=limit)\n",
    "        \n",
    "        retrived_documents = {}\n",
    "        max_score = None\n",
    "        for i,document in enumerate(results):\n",
    "            \n",
    "            pmid = document.payload['pmid']\n",
    "            score = document.score\n",
    "            if i == 0:\n",
    "                # first score is the max\n",
    "                max_score = score\n",
    "            retrived_documents[document.id] = { 'pmid': pmid, 'score': round(score / max_score, 5) } \n",
    "\n",
    "        retrived_documents = self.reorder_pmid(retrived_documents)\n",
    "        \n",
    "        return retrived_documents\n",
    "    \n",
    "\n",
    "    def hybrid_query(self, query_lexical, query_semantic, lex_parameter = 0.5, semantic_parameter = 0.5, limit=10):\n",
    "        if (lex_parameter + semantic_parameter) > 1:\n",
    "            raise ValueError(\"Uncorrect parameters for Hybrid Queries\")\n",
    "        lexical_results = self.lexical_query(query_lexical, limit = limit) \n",
    "        semantic_results = self.semantic_query(query_semantic, limit)\n",
    "        max_score = 0\n",
    "        retrived_documents = {}\n",
    "        \n",
    "        for lex_pmid in lexical_results:\n",
    "            score = lexical_results[lex_pmid] * lex_parameter\n",
    "            if lex_pmid in semantic_results:\n",
    "                score += semantic_results[lex_pmid] * semantic_parameter\n",
    "\n",
    "            retrived_documents[lex_pmid] = score\n",
    "            max_score = max(max_score, score)\n",
    "            \n",
    "\n",
    "        for semantic_pmid in semantic_results:\n",
    "            if semantic_pmid not in lexical_results:\n",
    "                score = semantic_results[semantic_pmid] * semantic_parameter\n",
    "                retrived_documents[semantic_pmid] = score\n",
    "                max_score = max(max_score, score)\n",
    "                \n",
    "        return retrived_documents # just to have a starting point\n",
    "\n",
    "\n",
    "    def execute_query(self, query_str, query_type='lexical', lex_parameter = 0.5, semantic_parameter = 0.5,limit = 10,save = True, stopwords_preprocessing=True):\n",
    "        #print(\"Before = \",query_str)\n",
    "        text_query = self.preprocess_query(query_str) if stopwords_preprocessing else query_str\n",
    "        \n",
    "        if query_type == 'lexical':\n",
    "            results = self.lexical_query(text_query, limit=limit) \n",
    "        \n",
    "        elif query_type == 'semantic':\n",
    "            results = self.semantic_query(query_str, limit=limit)\n",
    "\n",
    "        elif query_type == 'hybrid':\n",
    "            results = self.hybrid_query(text_query, query_str, lex_parameter, semantic_parameter, limit=limit)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid query type specified. Choose 'lexical', 'semantic', or 'hybrid'.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        document_retrived = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "        document_retrived = document_retrived[:limit+1] # in the hybrid search we can return more documents\n",
    "        #print(\"Results \", document_retrived)\n",
    "        if save:\n",
    "            self.process_results(document_retrived, query_str, query_type)\n",
    "\n",
    "        return document_retrived\n",
    "    \n",
    "    # needs to be rewrited\n",
    "    def process_results(self, results, query_str,query_type):\n",
    "        \n",
    "        retrieved_documents = []\n",
    "        for element in results:\n",
    "            \n",
    "            pmid,_ = element\n",
    "            query = {\n",
    "                    \"query\": {\n",
    "                        \"term\": {\n",
    "                        \"pmid\": int(pmid)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            results = self.lexical_client.search(index=self.index_lexical_name, body=query) \n",
    "            full_text = results['hits']['hits'][0][\"_source\"]['full_text']\n",
    "            pmid = results['hits']['hits'][0][\"_source\"]['pmid']\n",
    "\n",
    "            retrieved_documents.append({\n",
    "                \"pmid\": pmid,\n",
    "                \"text\": full_text\n",
    "            })\n",
    "\n",
    "        dict_to_save = {'query': query_str, 'query_type': query_type, 'abstracts' : retrieved_documents}\n",
    "        self.query_result.append(dict_to_save)  \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_parser = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10797929', 0.5),\n",
       " ('15877281', 0.5),\n",
       " ('37560515', 0.49687),\n",
       " ('29597095', 0.494725),\n",
       " ('20870045', 0.49326),\n",
       " ('29922639', 0.49277),\n",
       " ('9462748', 0.490925),\n",
       " ('22303795', 0.49066),\n",
       " ('24914010', 0.490565),\n",
       " ('19332160', 0.49053),\n",
       " ('22106036', 0.49053)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_parser.execute_query(query_str=\"Which gene is responsible for disfunction in speech for children?\", query_type='hybrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the evaluation file - BioASQ_10_or_more.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "evaluation_file = 'BioASQ_10_or_more.json'\n",
    "\n",
    "with open(evaluation_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(len(data['questions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def clean_documents(documents):\n",
    "    output_documents = []  ## Changed from output_documents = set()\n",
    "    for doc in documents:\n",
    "        output_documents.append((doc.replace(\"http://www.ncbi.nlm.nih.gov/pubmed/\",\"\")))\n",
    "    return output_documents\n",
    "\n",
    "def average_precision(retrived_doc, true_doc):\n",
    "    # Initialize variables\n",
    "    precision_sum = 0\n",
    "    num_retrieved_docs = 0\n",
    "    \n",
    "    # Calculate precision at each relevant document position\n",
    "    for i, retrived in enumerate(retrived_doc, start=1):\n",
    "        pmid,_ = retrived\n",
    "        if pmid in true_doc:  # Check if the document is relevant\n",
    "            num_retrieved_docs += 1\n",
    "            precision_sum += num_retrieved_docs / i  # Calculate precision at cutoff i\n",
    "\n",
    "    # Calculate average precision\n",
    "    if num_retrieved_docs == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return precision_sum / num_retrieved_docs\n",
    "\n",
    "\n",
    "def evaluation(query_parser, data, query_type,alpha=0.5, beta=0.5, stopwords_preprocessing = False, path = \"query_result.json\"):\n",
    "    avg_precisions_sum = [] # sum all average precision and divide with number of queries \n",
    "    precisions_sum = []\n",
    "    queries_time = []\n",
    "    for i,question in enumerate(data['questions']):\n",
    "        dict_to_save = {}\n",
    "        query = question['body']\n",
    "        dict_to_save['query'] = query\n",
    "        dict_to_save['query_type'] = query_type\n",
    "        #relevant_documents = clean_documents(question['documents'])\n",
    "        #(NEW_EVAL)Return only the first 10 abstracts\n",
    "        relevant_documents = clean_documents(question['documents'])[:10]\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #results = query_parser.execute_query(query,query_type = query_type, lex_parameter = alpha, semantic_parameter = beta,limit = len(relevant_documents), save=False, stopwords_preprocessing = stopwords_preprocessing)\n",
    "       \n",
    "        #(NEW_EVAL)In the next line, limit is set to 10 for retrieving from our IR\n",
    "        results = query_parser.execute_query(query,query_type = query_type, lex_parameter = alpha, semantic_parameter = beta,limit = 10, save=False, stopwords_preprocessing = stopwords_preprocessing)\n",
    "\n",
    "        queries_time.append(time.time() - start_time)\n",
    "        \n",
    "        #results = [('20598273',1), ('4',1), ('6650562',1), ('2',1),('21995290',1),('15617541',1),('23001136',1),('8896569',1), ('12239580',1)]\n",
    "        dict_to_save['true_documents'] = relevant_documents\n",
    "        dict_to_save['retrieved_documents'] = results\n",
    "       \n",
    "\n",
    "    \n",
    "        number_retrieved_documents = 0\n",
    "        for pmid,_ in results:\n",
    "            if pmid in relevant_documents:\n",
    "                number_retrieved_documents +=1\n",
    "\n",
    "        precision = number_retrieved_documents / len(relevant_documents)\n",
    "        recall = number_retrieved_documents / len(relevant_documents)\n",
    "        avg_precision = average_precision(results, relevant_documents)\n",
    "        \n",
    "        precisions_sum.append(precision)\n",
    "        #recalls.append(recall)\n",
    "        \n",
    "        avg_precisions_sum.append(avg_precision)\n",
    "        \n",
    "        dict_to_save['precision'] = precision\n",
    "        #dict_to_save['recall'] = recall\n",
    "        dict_to_save['avg_precision'] = avg_precision\n",
    "        with open(path, 'a') as output_file:\n",
    "            output_file.write(json.dumps(dict_to_save) + '\\n')\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f\"Analyzed {i+1} queries\")\n",
    "            print(\"Actual Results...\")\n",
    "            print(f\"Mean precision = {np.mean(precisions_sum):.3f}\")\n",
    "            #print(f\"Mean recall = {np.mean(recalls):.3f}\")\n",
    "            print(f\"Mean Average Precision = {np.mean(avg_precisions_sum):.3f}\")\n",
    "            print(f\"Mean Time needed to execute a query = {np.mean(queries_time):.3f}\")\n",
    "    print(\"FINAL RESULTS \")\n",
    "    print(f\"Mean precision = {np.mean(precisions_sum):.3f}\")\n",
    "    #print(f\"Mean recall = {np.mean(recalls):.3f}\")\n",
    "    print(f\"Mean Average Precision = {np.mean(avg_precisions_sum):.3f}\")\n",
    "    print(f\"Mean Time needed to execute a query = {np.mean(queries_time):.3f}\")\n",
    "    print('Relevantni',relevant_documents)\n",
    "    print('Vraćeni',results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Lexical Auto-id Stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.139\n",
      "Mean Average Precision = 0.289\n",
      "Mean Time needed to execute a query = 0.222\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.142\n",
      "Mean Average Precision = 0.289\n",
      "Mean Time needed to execute a query = 0.218\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.165\n",
      "Mean Average Precision = 0.321\n",
      "Mean Time needed to execute a query = 0.217\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.162\n",
      "Mean Average Precision = 0.322\n",
      "Mean Time needed to execute a query = 0.217\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 1.0), ('31490656', 0.93217), ('34698396', 0.92664), ('28388412', 0.92544), ('30136239', 0.91816), ('35365636', 0.8957), ('34764207', 0.8733), ('37511074', 0.87262), ('37922978', 0.86799), ('33848465', 0.86518)]\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser,data, query_type=\"lexical\", path = \"Eval_results_BioASQ_subset/lexical_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Lexical Pmid Stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "query_parser_pmid = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=True, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.143\n",
      "Mean Average Precision = 0.294\n",
      "Mean Time needed to execute a query = 0.202\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.146\n",
      "Mean Average Precision = 0.296\n",
      "Mean Time needed to execute a query = 0.204\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.168\n",
      "Mean Average Precision = 0.330\n",
      "Mean Time needed to execute a query = 0.206\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.166\n",
      "Mean Average Precision = 0.331\n",
      "Mean Time needed to execute a query = 0.208\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 1.0), ('31490656', 0.9305325716698989), ('34698396', 0.9270808026361854), ('28388412', 0.9269893363414594), ('30136239', 0.9132803947609708), ('35365636', 0.8995505315158622), ('37511074', 0.8739989553059898), ('34764207', 0.8685736036942159), ('37922978', 0.8652094389215201), ('37365800', 0.862840845313047)]\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser_pmid,data, query_type=\"lexical\", path = \"Eval_results_BioASQ_subset/lexical_results_pmid.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result lexical pmid with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'more', 'those', 'not', \"won't\", 'these', \"shouldn't\", 'over', 'were', 'o', 'should', 'her', 'whom', 'too', 'when', 'no', 'our', \"don't\", \"didn't\", \"mightn't\", 'i', 'during', 'why', 'd', 'shan', 'then', 'by', 'is', 'can', 'any', \"hasn't\", 'against', 'll', 'there', \"weren't\", 'once', 'he', 'yourselves', \"doesn't\", 'and', 'just', 'about', 'here', 'such', 'ours', 'ourselves', \"you'd\", 'nor', 'of', \"aren't\", \"mustn't\", 'or', 'myself', \"haven't\", 'my', 'have', 'only', 'do', 'so', 've', 'own', 'was', 'what', 'again', 'until', 'ma', 'yours', 'each', 'wouldn', 'above', 'that', 'been', 'shouldn', 'below', 'a', \"shan't\", 'from', 'further', 'doing', 'few', 'did', 'with', 'mightn', \"you'll\", \"isn't\", 'but', 's', \"that'll\", \"hadn't\", \"wasn't\", 'to', \"wouldn't\", 'theirs', 'hadn', 'if', 'for', 'couldn', 'himself', 'does', 'into', \"needn't\", 'its', 'same', 'are', 'itself', 'she', 'ain', 'weren', 'most', 'it', 'after', 'out', \"couldn't\", 'had', 're', 'how', 'some', 'an', 'hasn', 'under', 'very', 'who', 'them', 'while', 'you', 'on', 'the', 'as', 'through', \"you've\", 'than', 'don', 'isn', 'me', 'mustn', 'hers', \"she's\", 'they', 'at', 'will', 'between', 'other', 'won', 'aren', 'up', 'where', 'haven', 'their', \"should've\", \"it's\", 'all', 'needn', 'both', 'y', 'having', 'yourself', 'm', 'didn', 'now', 'down', 'off', 'be', 'being', 'your', 'herself', 'which', 'themselves', 'because', 'him', 'we', 'in', 'doesn', 'has', 'before', 'this', 'am', 't', 'wasn', 'his', \"you're\"}\n"
     ]
    }
   ],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "print(english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.146\n",
      "Mean Average Precision = 0.308\n",
      "Mean Time needed to execute a query = 0.204\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.148\n",
      "Mean Average Precision = 0.305\n",
      "Mean Time needed to execute a query = 0.196\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.169\n",
      "Mean Average Precision = 0.335\n",
      "Mean Time needed to execute a query = 0.195\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.165\n",
      "Mean Average Precision = 0.335\n",
      "Mean Time needed to execute a query = 0.193\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 1.0), ('31490656', 0.9304463543344844), ('34698396', 0.9269975080842887), ('28388412', 0.9268917074116443), ('30136239', 0.9132068197774056), ('35365636', 0.8994613475709672), ('37511074', 0.8739083591091045), ('34764207', 0.8684875684070689), ('37922978', 0.8651145640364755), ('37365800', 0.8627494312692764)]\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser_stopwords,data, query_type=\"lexical\", path = \"Eval_results_BioASQ_subset/lex_results_stopwords.json\",stopwords_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result lexical autoid stopword True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.143\n",
      "Mean Average Precision = 0.300\n",
      "Mean Time needed to execute a query = 0.195\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.145\n",
      "Mean Average Precision = 0.297\n",
      "Mean Time needed to execute a query = 0.188\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.165\n",
      "Mean Average Precision = 0.326\n",
      "Mean Time needed to execute a query = 0.186\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.162\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.185\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 1.0), ('31490656', 0.93192), ('34698396', 0.92639), ('28388412', 0.92514), ('30136239', 0.91794), ('35365636', 0.89543), ('34764207', 0.87305), ('37511074', 0.87235), ('37922978', 0.86771), ('37365800', 0.86354)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical\"\n",
    "lexical_pmid = False\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "evaluation(query_parser_stopwords,data, query_type=\"lexical\", path = \"Eval_results_BioASQ_subset/lex_results_stopwords_auto_id.json\",stopwords_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Semantic without rescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.086\n",
      "Mean Average Precision = 0.216\n",
      "Mean Time needed to execute a query = 0.201\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.089\n",
      "Mean Average Precision = 0.220\n",
      "Mean Time needed to execute a query = 0.199\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.096\n",
      "Mean Average Precision = 0.238\n",
      "Mean Time needed to execute a query = 0.197\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.099\n",
      "Mean Average Precision = 0.245\n",
      "Mean Time needed to execute a query = 0.197\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('28388403', 1.0), ('29076500', 0.98992), ('16377620', 0.9868), ('32931899', 0.98448), ('22351266', 0.97915), ('22157748', 0.97701), ('15221519', 0.97636), ('33687702', 0.97629), ('20010783', 0.97575), ('16023831', 0.97531)]\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser,data, query_type=\"semantic\", path = \"Eval_results_BioASQ_subset/semantic_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Semantic with rescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.087\n",
      "Mean Average Precision = 0.230\n",
      "Mean Time needed to execute a query = 0.205\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.090\n",
      "Mean Average Precision = 0.232\n",
      "Mean Time needed to execute a query = 0.205\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.097\n",
      "Mean Average Precision = 0.249\n",
      "Mean Time needed to execute a query = 0.202\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.100\n",
      "Mean Average Precision = 0.253\n",
      "Mean Time needed to execute a query = 0.204\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('28388403', 1.0), ('29076500', 0.9851), ('32931899', 0.98391), ('16377620', 0.98089), ('16023831', 0.97981), ('22157748', 0.97606), ('33687702', 0.9755), ('22351266', 0.97539), ('20010783', 0.975), ('10570775', 0.97352)]\n"
     ]
    }
   ],
   "source": [
    "query_parser.set_rescore(True)\n",
    "evaluation(query_parser,data, query_type=\"semantic\", path = \"Eval_results_BioASQ_subset/semantic_results.json\")\n",
    "query_parser.set_rescore(False) # re insert the rescore to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Hybrid with lexical autoid Stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.114\n",
      "Mean Average Precision = 0.285\n",
      "Mean Time needed to execute a query = 0.699\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.115\n",
      "Mean Average Precision = 0.287\n",
      "Mean Time needed to execute a query = 0.667\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.125\n",
      "Mean Average Precision = 0.315\n",
      "Mean Time needed to execute a query = 0.650\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.126\n",
      "Mean Average Precision = 0.318\n",
      "Mean Time needed to execute a query = 0.641\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.5), ('28388403', 0.5), ('29076500', 0.49496), ('16377620', 0.4934), ('32931899', 0.49224), ('22351266', 0.489575), ('22157748', 0.488505), ('15221519', 0.48818), ('33687702', 0.488145), ('20010783', 0.487875), ('16023831', 0.487655)]\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser, data, query_type=\"hybrid\", path = \"Eval_results_BioASQ_subset/hybrid_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Hybrid with lexical pmid Stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.112\n",
      "Mean Average Precision = 0.287\n",
      "Mean Time needed to execute a query = 0.569\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.114\n",
      "Mean Average Precision = 0.289\n",
      "Mean Time needed to execute a query = 0.567\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.124\n",
      "Mean Average Precision = 0.322\n",
      "Mean Time needed to execute a query = 0.542\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.126\n",
      "Mean Average Precision = 0.326\n",
      "Mean Time needed to execute a query = 0.543\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.5), ('28388403', 0.5), ('29076500', 0.49496), ('16377620', 0.4934), ('32931899', 0.49224), ('22351266', 0.489575), ('22157748', 0.488505), ('15221519', 0.48818), ('33687702', 0.488145), ('20010783', 0.487875), ('16023831', 0.487655)]\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser_pmid, data, query_type=\"hybrid\", path = \"Eval_results_BioASQ_subset/hybrid_results_pmid.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid pmid with stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.112\n",
      "Mean Average Precision = 0.297\n",
      "Mean Time needed to execute a query = 0.476\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.114\n",
      "Mean Average Precision = 0.298\n",
      "Mean Time needed to execute a query = 0.457\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.124\n",
      "Mean Average Precision = 0.324\n",
      "Mean Time needed to execute a query = 0.450\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.126\n",
      "Mean Average Precision = 0.327\n",
      "Mean Time needed to execute a query = 0.446\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.5), ('28388403', 0.5), ('29076500', 0.49496), ('16377620', 0.4934), ('32931899', 0.49224), ('22351266', 0.489575), ('22157748', 0.488505), ('15221519', 0.48818), ('33687702', 0.488145), ('20010783', 0.487875), ('16023831', 0.487655)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.5, beta=0.5, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_stopwords.json\", stopwords_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid autoid with stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.114\n",
      "Mean Average Precision = 0.294\n",
      "Mean Time needed to execute a query = 0.542\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.115\n",
      "Mean Average Precision = 0.293\n",
      "Mean Time needed to execute a query = 0.499\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.124\n",
      "Mean Average Precision = 0.321\n",
      "Mean Time needed to execute a query = 0.480\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.127\n",
      "Mean Average Precision = 0.322\n",
      "Mean Time needed to execute a query = 0.479\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.5), ('28388403', 0.5), ('29076500', 0.49496), ('16377620', 0.4934), ('32931899', 0.49224), ('22351266', 0.489575), ('22157748', 0.488505), ('15221519', 0.48818), ('33687702', 0.488145), ('20010783', 0.487875), ('16023831', 0.487655)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical\"\n",
    "lexical_pmid = False\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.5, beta=0.5, path = \"Eval_results_BioASQ_subset/hybrid_results_autoid_stopwords.json\", stopwords_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid pmid with rescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.115\n",
      "Mean Average Precision = 0.300\n",
      "Mean Time needed to execute a query = 0.482\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.116\n",
      "Mean Average Precision = 0.298\n",
      "Mean Time needed to execute a query = 0.480\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.126\n",
      "Mean Average Precision = 0.326\n",
      "Mean Time needed to execute a query = 0.479\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.128\n",
      "Mean Average Precision = 0.327\n",
      "Mean Time needed to execute a query = 0.480\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.5), ('28388403', 0.5), ('29076500', 0.49255), ('32931899', 0.491955), ('16377620', 0.490445), ('16023831', 0.489905), ('22157748', 0.48803), ('33687702', 0.48775), ('22351266', 0.487695), ('20010783', 0.4875), ('10570775', 0.48676)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.5, beta=0.5, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid 0.6 lexical and 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.154\n",
      "Mean Average Precision = 0.306\n",
      "Mean Time needed to execute a query = 0.500\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.157\n",
      "Mean Average Precision = 0.308\n",
      "Mean Time needed to execute a query = 0.481\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.178\n",
      "Mean Average Precision = 0.339\n",
      "Mean Time needed to execute a query = 0.469\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.175\n",
      "Mean Average Precision = 0.340\n",
      "Mean Time needed to execute a query = 0.466\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.6), ('31490656', 0.5582678126006906), ('34698396', 0.5561985048505732), ('28388412', 0.5561350244469866), ('30136239', 0.5479240918664433), ('35365636', 0.5396768085425803), ('37511074', 0.5243450154654626), ('34764207', 0.5210925410442413), ('37922978', 0.5190687384218853), ('37365800', 0.5176496587615658), ('28388403', 0.4)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.6, beta=0.4, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore_06-04.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with alpha 0.7 and Beta 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.154\n",
      "Mean Average Precision = 0.307\n",
      "Mean Time needed to execute a query = 0.459\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.157\n",
      "Mean Average Precision = 0.310\n",
      "Mean Time needed to execute a query = 0.460\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.179\n",
      "Mean Average Precision = 0.343\n",
      "Mean Time needed to execute a query = 0.464\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.176\n",
      "Mean Average Precision = 0.343\n",
      "Mean Time needed to execute a query = 0.465\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.7), ('31490656', 0.651312448034139), ('34698396', 0.648898255659002), ('28388412', 0.6488241951881509), ('30136239', 0.6392447738441839), ('35365636', 0.6296229432996769), ('37511074', 0.6117358513763731), ('34764207', 0.6079412978849482), ('37922978', 0.6055801948255328), ('37365800', 0.6039246018884934), ('28388403', 0.3)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.7, beta=0.3, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore_07-03.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.8 and 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.154\n",
      "Mean Average Precision = 0.309\n",
      "Mean Time needed to execute a query = 0.460\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.157\n",
      "Mean Average Precision = 0.311\n",
      "Mean Time needed to execute a query = 0.456\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.179\n",
      "Mean Average Precision = 0.343\n",
      "Mean Time needed to execute a query = 0.450\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.176\n",
      "Mean Average Precision = 0.344\n",
      "Mean Time needed to execute a query = 0.451\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.8), ('31490656', 0.7443570834675876), ('34698396', 0.741598006467431), ('28388412', 0.7415133659293155), ('30136239', 0.7305654558219246), ('35365636', 0.7195690780567738), ('37511074', 0.6991266872872837), ('34764207', 0.6947900547256551), ('37922978', 0.6920916512291804), ('37365800', 0.6901995450154211), ('28388403', 0.2)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.8, beta=0.2, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore_08-02.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.9 lexical and 0.1 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.154\n",
      "Mean Average Precision = 0.309\n",
      "Mean Time needed to execute a query = 0.458\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.157\n",
      "Mean Average Precision = 0.311\n",
      "Mean Time needed to execute a query = 0.454\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.179\n",
      "Mean Average Precision = 0.343\n",
      "Mean Time needed to execute a query = 0.450\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.176\n",
      "Mean Average Precision = 0.344\n",
      "Mean Time needed to execute a query = 0.455\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('31138766', 0.8), ('31490656', 0.7443570834675876), ('34698396', 0.741598006467431), ('28388412', 0.7415133659293155), ('30136239', 0.7305654558219246), ('35365636', 0.7195690780567738), ('37511074', 0.6991266872872837), ('34764207', 0.6947900547256551), ('37922978', 0.6920916512291804), ('37365800', 0.6901995450154211), ('28388403', 0.2)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.8, beta=0.2, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore_09-01.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.4 lexical and 0.6 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.109\n",
      "Mean Average Precision = 0.263\n",
      "Mean Time needed to execute a query = 0.461\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.111\n",
      "Mean Average Precision = 0.258\n",
      "Mean Time needed to execute a query = 0.471\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.120\n",
      "Mean Average Precision = 0.278\n",
      "Mean Time needed to execute a query = 0.479\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.122\n",
      "Mean Average Precision = 0.281\n",
      "Mean Time needed to execute a query = 0.480\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('28388403', 0.6), ('29076500', 0.5910599999999999), ('32931899', 0.5903459999999999), ('16377620', 0.588534), ('16023831', 0.5878859999999999), ('22157748', 0.585636), ('33687702', 0.5853), ('22351266', 0.5852339999999999), ('20010783', 0.585), ('10570775', 0.584112), ('31138766', 0.4)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.4, beta=0.6, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore_04-06.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.3 lexical and 0.7 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.109\n",
      "Mean Average Precision = 0.263\n",
      "Mean Time needed to execute a query = 0.496\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.111\n",
      "Mean Average Precision = 0.258\n",
      "Mean Time needed to execute a query = 0.479\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.120\n",
      "Mean Average Precision = 0.277\n",
      "Mean Time needed to execute a query = 0.476\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.122\n",
      "Mean Average Precision = 0.279\n",
      "Mean Time needed to execute a query = 0.471\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('28388403', 0.7), ('29076500', 0.6895699999999999), ('32931899', 0.6887369999999999), ('16377620', 0.686623), ('16023831', 0.6858669999999999), ('22157748', 0.683242), ('33687702', 0.68285), ('22351266', 0.682773), ('20010783', 0.6825), ('10570775', 0.681464), ('31138766', 0.3)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.3, beta=0.7, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore_03-07.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.2 lexical and 0.8 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.109\n",
      "Mean Average Precision = 0.263\n",
      "Mean Time needed to execute a query = 0.497\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.111\n",
      "Mean Average Precision = 0.257\n",
      "Mean Time needed to execute a query = 0.480\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.120\n",
      "Mean Average Precision = 0.277\n",
      "Mean Time needed to execute a query = 0.470\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.122\n",
      "Mean Average Precision = 0.279\n",
      "Mean Time needed to execute a query = 0.490\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('28388403', 0.8), ('29076500', 0.78808), ('32931899', 0.787128), ('16377620', 0.7847120000000001), ('16023831', 0.783848), ('22157748', 0.7808480000000001), ('33687702', 0.7804000000000001), ('22351266', 0.780312), ('20010783', 0.78), ('10570775', 0.7788160000000001), ('31138766', 0.2)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.2, beta=0.8, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore_02-08.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.1 lexical and 0.9 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.109\n",
      "Mean Average Precision = 0.260\n",
      "Mean Time needed to execute a query = 0.529\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.111\n",
      "Mean Average Precision = 0.256\n",
      "Mean Time needed to execute a query = 0.531\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.120\n",
      "Mean Average Precision = 0.278\n",
      "Mean Time needed to execute a query = 0.528\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.122\n",
      "Mean Average Precision = 0.279\n",
      "Mean Time needed to execute a query = 0.521\n",
      "Relevantni ['33848465', '27158445', '31138766', '35365636', '30709919', '28388412', '30148498', '31766571', '30344099', '32839552']\n",
      "Vraćeni [('28388403', 0.9), ('29076500', 0.88659), ('32931899', 0.885519), ('16377620', 0.8828010000000001), ('16023831', 0.881829), ('22157748', 0.8784540000000001), ('33687702', 0.87795), ('22351266', 0.877851), ('20010783', 0.8775), ('10570775', 0.8761680000000001), ('31138766', 0.1)]\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.1, beta=0.9, path = \"Eval_results_BioASQ_subset/hybrid_results_pmid_recore_01-09.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation based on PubMed website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id list =  ['11076767', '15094110', '38284126', '22242013', '30388611', '22937083', '30661986', '12666201', '36997062', '29678203']\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "# Always tell NCBI who you are (your email address)\n",
    "Entrez.email = \"adela.ljajic@ivi.ac.rs\"\n",
    "def search_pubmed(query, limit = 10, mesh=True):\n",
    "    if not mesh:\n",
    "        query += \"[Title/Abstract]\"\n",
    "    # Use Entrez.esearch to search for articles matching the query in PubMed\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=limit, sort=\"relevance\",)\n",
    "    \n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    # Get the list of Ids returned by the search\n",
    "    id_list = record[\"IdList\"]\n",
    "    return id_list\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    # Use Entrez.efetch to get the article details from the list of Ids\n",
    "    ids = ','.join(id_list)\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=ids, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return records\n",
    "# Example usage\n",
    "\n",
    "query = \"Is the protein Papilin secreted?\"\n",
    "id_list = search_pubmed(query)\n",
    "print(\"Id list = \",id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id list =  ['38284126', '11076767', '15094122', '21784067', '7515725']\n"
     ]
    }
   ],
   "source": [
    "query = \"Is the protein Papilin secreted?\"\n",
    "id_list = search_pubmed(query, mesh=False)\n",
    "print(\"Id list = \",id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_pubmed(query_type, data,mesh=True,path = \"query_result.json\"):\n",
    "    avg_precisions_sum = [] # sum all average precision and divide with number of queries \n",
    "    precisions_sum = []\n",
    "    queries_time = []\n",
    "    for i,question in enumerate(data['questions']):\n",
    "        dict_to_save = {}\n",
    "        query = question['body']\n",
    "        dict_to_save['query'] = query\n",
    "        dict_to_save['query_type'] = query_type\n",
    "        relevant_documents = clean_documents(question['documents'])\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = search_pubmed(query, limit = len(relevant_documents),mesh=mesh)\n",
    "        queries_time.append(time.time() - start_time)\n",
    "        \n",
    "        dict_to_save['true_documents'] = list(relevant_documents)\n",
    "        dict_to_save['retrieved_documents'] = results\n",
    "       \n",
    "        number_retrieved_documents = 0\n",
    "        for pmid in results:\n",
    "            if pmid in relevant_documents:\n",
    "                number_retrieved_documents +=1\n",
    "\n",
    "        precision = number_retrieved_documents / len(relevant_documents)\n",
    "        recall = number_retrieved_documents / len(relevant_documents)\n",
    "        avg_precision = average_precision(results, relevant_documents)\n",
    "       \n",
    "        precisions_sum.append(precision)\n",
    "        #recalls.append(recall)\n",
    "        \n",
    "        avg_precisions_sum.append(avg_precision)\n",
    "        \n",
    "        dict_to_save['precision'] = precision\n",
    "        #dict_to_save['recall'] = recall\n",
    "        dict_to_save['avg_precision'] = avg_precision\n",
    "        with open(path, 'a') as output_file:\n",
    "            output_file.write(json.dumps(dict_to_save) + '\\n')\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f\"Analyzed {i+1} queries\")\n",
    "            print(\"Actual Results...\")\n",
    "            print(f\"Mean precision = {np.mean(precisions_sum):.3f}\")\n",
    "            #print(f\"Mean recall = {np.mean(recalls):.3f}\")\n",
    "            print(f\"Mean Average Precision = {np.mean(avg_precisions_sum):.3f}\")\n",
    "            print(f\"Mean Time needed to execute a query = {np.mean(queries_time):.3f}\")\n",
    "    print(\"FINAL RESULTS \")\n",
    "    print(f\"Mean precision = {np.mean(precisions_sum):.3f}\")\n",
    "    #print(f\"Mean recall = {np.mean(recalls):.3f}\")\n",
    "    print(f\"Mean Average Precision = {np.mean(avg_precisions_sum):.3f}\")\n",
    "    print(f\"Mean Time needed to execute a query = {np.mean(queries_time):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pubmed with Mesh Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mesh terms are applied automatically by PubMed website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evaluation_pubmed(data\u001b[38;5;241m=\u001b[39mdata, query_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPubMed website\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval_results_BioASQ_subset/Pubmed_mesh.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 26\u001b[0m, in \u001b[0;36mevaluation_pubmed\u001b[1;34m(query_type, data, mesh, path)\u001b[0m\n\u001b[0;32m     24\u001b[0m precision \u001b[38;5;241m=\u001b[39m number_retrieved_documents \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(relevant_documents)\n\u001b[0;32m     25\u001b[0m recall \u001b[38;5;241m=\u001b[39m number_retrieved_documents \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(relevant_documents)\n\u001b[1;32m---> 26\u001b[0m avg_precision \u001b[38;5;241m=\u001b[39m average_precision(results, relevant_documents)\n\u001b[0;32m     28\u001b[0m precisions_sum\u001b[38;5;241m.\u001b[39mappend(precision)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#recalls.append(recall)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m, in \u001b[0;36maverage_precision\u001b[1;34m(retrived_doc, true_doc)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Calculate precision at each relevant document position\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, retrived \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(retrived_doc, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     pmid,_ \u001b[38;5;241m=\u001b[39m retrived\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pmid \u001b[38;5;129;01min\u001b[39;00m true_doc:  \u001b[38;5;66;03m# Check if the document is relevant\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         num_retrieved_docs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "evaluation_pubmed(data=data, query_type=\"PubMed website\", path=\"Eval_results_BioASQ_subset/Pubmed_mesh.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation PubMed without mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_pubmed(data=data, query_type=\"PubMed website no mash\", mesh = False, path=\"Eval_results_BioASQ_subset/Pubmed_no_mesh.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
