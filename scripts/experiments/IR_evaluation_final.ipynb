{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "from opensearchpy import OpenSearch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "model_card = 'sentence-transformers/msmarco-distilbert-base-tas-b'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened...\n"
     ]
    }
   ],
   "source": [
    "host = '3.23.103.76' #host = 'localhost' \n",
    "port = 9200\n",
    "auth =('admin','IVIngi2024!') #auth = ('admin','admin') \n",
    "client_lexical = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    "    timeout=500, \n",
    "    max_retries=1\n",
    "    #connection_class=RequestsHttpConnection \n",
    "#    http_compress = True, # enables gzip compression for request bodies\n",
    "#    use_ssl = False,\n",
    "#   verify_certs = False,\n",
    "#    ssl_assert_hostname = False,\n",
    "#    ssl_show_warn = False\n",
    ")\n",
    "print(\"Connection opened...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 44, 'timed_out': False, '_shards': {'total': 4, 'successful': 4, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 10000, 'relation': 'gte'}, 'max_score': 18.928892, 'hits': [{'_index': 'medline-faiss-hnsw-lexical', '_id': '2298154', '_score': 18.928892, '_source': {'pmid': '15868453', 'auto_id': 2298154, 'text': \"What do cancer survivors believe causes cancer? (United States). OBJECTIVE To describe cancer survivors' beliefs about the causes of prostate, colorectal or breast cancers. METHODS A survey of beliefs about cancer causation was completed by 670 cancer survivors (416 with breast cancer, 165 with prostate cancer and 89 with colorectal cancer) enrolled in a population-based study in Colorado. Categorical analysis was used to describe associations between participant's beliefs about the cause of their cancer type, both in themselves and in others, and personal characteristics, including gender, age, and familial cancer risk. RESULTS Cancer survivors most frequently reported genetic factors, smoking, environmental factors (e.g., pollutants or occupation), and psychosocial factors (e.g., stress) as causing their type of cancer. Respondents underestimated the importance of behavioral factors that are known to be associated with increased cancer risk, such as obesity and physical inactivity, while overestimating the importance of stress and environmental pollution. CONCLUSIONS Cancer survivors' beliefs about what causes cancer are substantially different than those of experts. Because those affected by cancer should be well informed about the causes of cancer, educational efforts are needed, especially regarding the importance of factors that can be modified to reduce cancer risk.\", 'full_text': \"What do cancer survivors believe causes cancer? (United States).\\n\\nOBJECTIVE\\nTo describe cancer survivors' beliefs about the causes of prostate, colorectal or breast cancers.\\n\\n\\nMETHODS\\nA survey of beliefs about cancer causation was completed by 670 cancer survivors (416 with breast cancer, 165 with prostate cancer and 89 with colorectal cancer) enrolled in a population-based study in Colorado. Categorical analysis was used to describe associations between participant's beliefs about the cause of their cancer type, both in themselves and in others, and personal characteristics, including gender, age, and familial cancer risk.\\n\\n\\nRESULTS\\nCancer survivors most frequently reported genetic factors, smoking, environmental factors (e.g., pollutants or occupation), and psychosocial factors (e.g., stress) as causing their type of cancer. Respondents underestimated the importance of behavioral factors that are known to be associated with increased cancer risk, such as obesity and physical inactivity, while overestimating the importance of stress and environmental pollution.\\n\\n\\nCONCLUSIONS\\nCancer survivors' beliefs about what causes cancer are substantially different than those of experts. Because those affected by cancer should be well informed about the causes of cancer, educational efforts are needed, especially regarding the importance of factors that can be modified to reduce cancer risk.\", 'authors': [{'lastname': 'Wold', 'forename': 'Kimberly S', 'initials': 'KS', 'identifier': '', 'affiliation': 'Division of Cancer Prevention and Control, University of Colorado Cancer Center, Denver, CO, USA.'}, {'lastname': 'Byers', 'forename': 'Tim', 'initials': 'T', 'identifier': '', 'affiliation': ''}, {'lastname': 'Crane', 'forename': 'Lori A', 'initials': 'LA', 'identifier': '', 'affiliation': ''}, {'lastname': 'Ahnen', 'forename': 'Dennis', 'initials': 'D', 'identifier': '', 'affiliation': ''}], 'journal': 'Cancer causes & control : CCC', 'pubdate': '2005-03'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '2090351', '_score': 18.928036, '_source': {'pmid': '15613283', 'auto_id': 2090351, 'text': 'Multiple numerical chromosome aberrations in cancer: what are their causes and what are their consequences? Several neoplastic tumor types are cytogenetically characterized by multiple numerical chromosome abnormalities without concomitant structural karyotypic changes. At present, no good gene-level theories are at hand to explain the pathogenetic effect of these changes during tumorigenesis, nor is it known how they arise or what causes them. Genetic instability is often invoked as an underlying cause, but actual data favoring this explanation are meager or non-existing. Numerical chromosome changes and ploidy shifts allow the simultaneous alteration of multiple cancer-relevant genes, thereby reducing the number of independent genomic events necessary for carcinogenesis and the need for postulating genomic instability as a necessity in cancer development.', 'full_text': 'Multiple numerical chromosome aberrations in cancer: what are their causes and what are their consequences?\\n\\nSeveral neoplastic tumor types are cytogenetically characterized by multiple numerical chromosome abnormalities without concomitant structural karyotypic changes. At present, no good gene-level theories are at hand to explain the pathogenetic effect of these changes during tumorigenesis, nor is it known how they arise or what causes them. Genetic instability is often invoked as an underlying cause, but actual data favoring this explanation are meager or non-existing. Numerical chromosome changes and ploidy shifts allow the simultaneous alteration of multiple cancer-relevant genes, thereby reducing the number of independent genomic events necessary for carcinogenesis and the need for postulating genomic instability as a necessity in cancer development.', 'authors': [{'lastname': 'Teixeira', 'forename': 'Manuel R', 'initials': 'MR', 'identifier': '', 'affiliation': 'Department of Genetics, Portuguese Oncology Institute, Rua Dr. AntÃ³nio Bernardino de Almeida, 4200-072 Porto, Portugal. mteixeir@ipoporto.min-saude.pt'}, {'lastname': 'Heim', 'forename': 'Sverre', 'initials': 'S', 'identifier': '', 'affiliation': ''}], 'journal': 'Seminars in cancer biology', 'pubdate': '2005-02'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '14805642', '_score': 18.776869, '_source': {'pmid': '31345063', 'auto_id': 14805642, 'text': 'What Caused My Cancer? Cancer Patients\\' Perceptions on What May Have Contributed to the Development of Their Cancer: A Cross-Sectional, Cross-Country Comparison Study. Accurate public perceptions on the risk factors associated with cancer are important in promoting primary, secondary, and tertiary prevention. Limited studies have explored this topic among patients with cancer in non-western, low-to-middle-income countries. A cross-sectional survey to compare Australian and Vietnamese cancer patients\\' perceptions of what caused their cancer was undertaken. Adult, patients with cancer from both countries, receiving radiotherapy treatment completed a standardized survey, which included a 25-item module assessing their beliefs on the causes of their cancer. Items ranged from known evidence-based causes (eg, smoking, sun exposure) to non-evidence-based beliefs (eg, stress or anxiety, physical injury, or trauma). Country-specific logistic regression analyses were conducted to identify differences in the determinants of patients\\' top perceived causes. A total of 585 patient surveys were completed (75% response rate; 285 from Australia, and 300 from Vietnam). Most patients were male (58%) and aged 60 years and older (55%). The most frequently reported risk factor overall and for the Australian sample was \"getting older\" (overall = 42%, Australia = 49%, and Vietnam = 35%). While the most frequently reported risk factor for the Vietnamese sample was \"poor diet\" (overall = 39%, Australia = 11%, and Vietnam = 64%). There were differences in the characteristics associated with the top causes of cancer identified by Australian and Vietnamese patients. Patients\\' beliefs about what may have caused their cancer are complex and likely to be impacted by multiple factors, including the country from which they reside. Developing public awareness campaigns that are accurate and tailored to address the specific beliefs and possible misconceptions held by the target community are needed.', 'full_text': 'What Caused My Cancer? Cancer Patients\\' Perceptions on What May Have Contributed to the Development of Their Cancer: A Cross-Sectional, Cross-Country Comparison Study.\\n\\nAccurate public perceptions on the risk factors associated with cancer are important in promoting primary, secondary, and tertiary prevention. Limited studies have explored this topic among patients with cancer in non-western, low-to-middle-income countries. A cross-sectional survey to compare Australian and Vietnamese cancer patients\\' perceptions of what caused their cancer was undertaken. Adult, patients with cancer from both countries, receiving radiotherapy treatment completed a standardized survey, which included a 25-item module assessing their beliefs on the causes of their cancer. Items ranged from known evidence-based causes (eg, smoking, sun exposure) to non-evidence-based beliefs (eg, stress or anxiety, physical injury, or trauma). Country-specific logistic regression analyses were conducted to identify differences in the determinants of patients\\' top perceived causes. A total of 585 patient surveys were completed (75% response rate; 285 from Australia, and 300 from Vietnam). Most patients were male (58%) and aged 60 years and older (55%). The most frequently reported risk factor overall and for the Australian sample was \"getting older\" (overall = 42%, Australia = 49%, and Vietnam = 35%). While the most frequently reported risk factor for the Vietnamese sample was \"poor diet\" (overall = 39%, Australia = 11%, and Vietnam = 64%). There were differences in the characteristics associated with the top causes of cancer identified by Australian and Vietnamese patients. Patients\\' beliefs about what may have caused their cancer are complex and likely to be impacted by multiple factors, including the country from which they reside. Developing public awareness campaigns that are accurate and tailored to address the specific beliefs and possible misconceptions held by the target community are needed.', 'authors': [{'lastname': 'Hall', 'forename': 'Alix', 'initials': 'A', 'identifier': 'https://orcid.org/0000-0002-1043-6110', 'affiliation': '1 Priority Research Centre for Health Behaviour, Faculty of Health, The University of Newcastle & Hunter Medical Research Institute, Callaghan, New South Wales, Australia.'}, {'lastname': 'Nguyen', 'forename': 'Sang Minh', 'initials': 'SM', 'identifier': '', 'affiliation': '2 Division of Epidemiology, Department of Medicine, Vanderbilt University School of Medicine, Nashville, TN, USA.'}, {'lastname': 'Mackenzie', 'forename': 'Lisa', 'initials': 'L', 'identifier': '', 'affiliation': '1 Priority Research Centre for Health Behaviour, Faculty of Health, The University of Newcastle & Hunter Medical Research Institute, Callaghan, New South Wales, Australia.'}, {'lastname': 'Sanson-Fisher', 'forename': 'Rob', 'initials': 'R', 'identifier': '', 'affiliation': '1 Priority Research Centre for Health Behaviour, Faculty of Health, The University of Newcastle & Hunter Medical Research Institute, Callaghan, New South Wales, Australia.'}, {'lastname': 'Olver', 'forename': 'Ian', 'initials': 'I', 'identifier': '', 'affiliation': '3 University of South Australia Cancer Research Institute, Adelaide, Australia.'}, {'lastname': 'Thuan', 'forename': 'Tran Van', 'initials': 'TV', 'identifier': '', 'affiliation': '4 National Cancer Hospital, National Cancer Institute, Hanoi, Vietnam.'}, {'lastname': 'Huong', 'forename': 'Tran Thanh', 'initials': 'TT', 'identifier': '', 'affiliation': '5 Vietnam National Cancer Institute, Hanoi Medical University, Hanoi, Vietnam.'}], 'journal': 'Cancer control : journal of the Moffitt Cancer Center', 'pubdate': '2019'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '21704390', '_score': 17.92782, '_source': {'pmid': '38282044', 'auto_id': 21704390, 'text': \"What do cancer survivors believe caused their cancer? A secondary analysis of cross-sectional survey data. PURPOSE Given that risk reduction and healthy lifestyles can prevent 4 in 10 cancers, it is important to understand what survivors believe caused their cancer to inform educational initiatives. METHODS In this secondary analysis, we analyzed cancer survivor responses on the Causes Subscale of the Revised Illness Perception Questionnaire, which lists 18 possible causes of illness and a free text question. We used descriptive statistics to determine cancer survivors' agreement with the listed causes and conducted separate partial proportional odds models for the top three causes to examine their associations with sociodemographic and clinical characteristics. Content analysis was used to examine free text responses. RESULTS Of the 1,001 participants, most identified as Caucasian (n\\u2009=\\u2009764, 77%), female (n\\u2009=\\u2009845, 85%), and were diagnosed with breast cancer (n\\u2009=\\u2009656, 66%). The most commonly believed causes of cancer were: stress or worry (n\\u2009=\\u2009498, 51%), pollution in the environment (n\\u2009=\\u2009471, 48%), and chance or bad luck (n\\u2009=\\u2009412, 42%). The associations of sociodemographic and clinical variables varied across the models. Free text responses indicated that hereditary and genetic causes (n\\u2009=\\u2009223, 22.3%) followed by trauma and stress (n\\u2009=\\u2009218, 21.8%) and bad luck or chance (n\\u2009=\\u200979, 7.9%) were the most important causes of cancer. CONCLUSIONS Study results illuminate cancer survivors' beliefs about varying causes of their cancer diagnosis and identify characteristics of survivors who are more likely to believe certain factors caused their cancer. Results can be used to plan cancer education and risk-reduction campaigns and highlight for whom such initiatives would be most suitable.\", 'full_text': \"What do cancer survivors believe caused their cancer? A secondary analysis of cross-sectional survey data.\\n\\nPURPOSE\\nGiven that risk reduction and healthy lifestyles can prevent 4 in 10 cancers, it is important to understand what survivors believe caused their cancer to inform educational initiatives.\\n\\n\\nMETHODS\\nIn this secondary analysis, we analyzed cancer survivor responses on the Causes Subscale of the Revised Illness Perception Questionnaire, which lists 18 possible causes of illness and a free text question. We used descriptive statistics to determine cancer survivors' agreement with the listed causes and conducted separate partial proportional odds models for the top three causes to examine their associations with sociodemographic and clinical characteristics. Content analysis was used to examine free text responses.\\n\\n\\nRESULTS\\nOf the 1,001 participants, most identified as Caucasian (n\\u2009=\\u2009764, 77%), female (n\\u2009=\\u2009845, 85%), and were diagnosed with breast cancer (n\\u2009=\\u2009656, 66%). The most commonly believed causes of cancer were: stress or worry (n\\u2009=\\u2009498, 51%), pollution in the environment (n\\u2009=\\u2009471, 48%), and chance or bad luck (n\\u2009=\\u2009412, 42%). The associations of sociodemographic and clinical variables varied across the models. Free text responses indicated that hereditary and genetic causes (n\\u2009=\\u2009223, 22.3%) followed by trauma and stress (n\\u2009=\\u2009218, 21.8%) and bad luck or chance (n\\u2009=\\u200979, 7.9%) were the most important causes of cancer.\\n\\n\\nCONCLUSIONS\\nStudy results illuminate cancer survivors' beliefs about varying causes of their cancer diagnosis and identify characteristics of survivors who are more likely to believe certain factors caused their cancer. Results can be used to plan cancer education and risk-reduction campaigns and highlight for whom such initiatives would be most suitable.\", 'authors': [{'lastname': 'Galica', 'forename': 'Jacqueline', 'initials': 'J', 'identifier': '', 'affiliation': \"Queen's University School of Nursing, 92 Barrie Street, Kingston, ON, K7L 3N6, Canada. jacqueline.galica@queensu.ca.\"}, {'lastname': 'Saunders', 'forename': 'Stephanie', 'initials': 'S', 'identifier': '', 'affiliation': 'The Ottawa Hospital, 1053 Carling Avenue, Ottawa, ON, K1Y 4E9, Canada.'}, {'lastname': 'Pan', 'forename': 'Ziwei', 'initials': 'Z', 'identifier': '', 'affiliation': \"Department of Mathematics and Statistics, Queen's University, 48 University Avenue, Kingston, ON, K7L 3N6, Canada.\"}, {'lastname': 'Silva', 'forename': 'Amina', 'initials': 'A', 'identifier': '', 'affiliation': 'Faculty of Applied Health Sciences, Brock University, 1812 Sir Isaac Brock Way, St. Catharines, ON, L2S 3A1, Canada.'}, {'lastname': 'Ling', 'forename': 'Hok Kan', 'initials': 'HK', 'identifier': '', 'affiliation': \"Department of Mathematics and Statistics, Queen's University, 48 University Avenue, Kingston, ON, K7L 3N6, Canada.\"}], 'journal': 'Cancer causes & control : CCC', 'pubdate': '2024-01-28'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '1628440', '_score': 17.860188, '_source': {'pmid': '14981975', 'auto_id': 1628440, 'text': 'Cancer cachexia: what is known about its etiology and what should be the current treatment approach? Cancer cachexia, defined as involuntary weight loss and tissue wasting due to cancer, negatively influences physical condition, quality of life and prognosis. Well known causes, such as ileus or hypercalcemia, do not suffice to explain the entire phenomenon. Metabolic changes induced by the tumor and/or host are supposed to play a deciding role. In the present review current insights into the etiology and treatment are discussed.', 'full_text': 'Cancer cachexia: what is known about its etiology and what should be the current treatment approach?\\n\\nCancer cachexia, defined as involuntary weight loss and tissue wasting due to cancer, negatively influences physical condition, quality of life and prognosis. Well known causes, such as ileus or hypercalcemia, do not suffice to explain the entire phenomenon. Metabolic changes induced by the tumor and/or host are supposed to play a deciding role. In the present review current insights into the etiology and treatment are discussed.', 'authors': [{'lastname': 'van Halteren', 'forename': 'H K', 'initials': 'HK', 'identifier': '', 'affiliation': 'Department of Internal Medicine, Oosterschelde Hospital, PO Box 106, 4460 BB Goes, The Netherlands. Hvanhalteren@soz.nl'}, {'lastname': 'Bongaerts', 'forename': 'G P', 'initials': 'GP', 'identifier': '', 'affiliation': ''}, {'lastname': 'Wagener', 'forename': 'D J', 'initials': 'DJ', 'identifier': '', 'affiliation': ''}], 'journal': 'Anticancer research', 'pubdate': '2003'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '27470363', '_score': 17.638792, '_source': {'pmid': '10664443', 'auto_id': 27470363, 'text': 'Cellular and molecular basis of preferential metastasis of breast cancer to bone. Bone is one of the most preferential target sites for cancer metastasis. Breast cancer has a predilection for spreading to bone, and bone metastasis is one of the major causes of increased morbidity and eventual mortality in breast cancer patients. None of the currently available therapies is effective for curing bone metastases in these patients. Elucidation of the cellular and molecular mechanism by which breast cancer selectively spreads to bone is essential for the development of mechanism-based effective and specific therapeutic interventions for this deleterious complication in breast cancer. Here, two questions are addressed to study the mechanism of breast cancer metastasis to bone: (1) What makes bone a preferential target site of metastasis? (2) What makes breast cancer able to colonize bone? (3) An animal model in which intracardiac inoculation of breast cancer cells selectively causes osteolytic bone metastases was developed. Experimental results obtained using this unique in-vivo model of bone metastasis are described and discussed.', 'full_text': 'Cellular and molecular basis of preferential metastasis of breast cancer to bone.\\n\\nBone is one of the most preferential target sites for cancer metastasis. Breast cancer has a predilection for spreading to bone, and bone metastasis is one of the major causes of increased morbidity and eventual mortality in breast cancer patients. None of the currently available therapies is effective for curing bone metastases in these patients. Elucidation of the cellular and molecular mechanism by which breast cancer selectively spreads to bone is essential for the development of mechanism-based effective and specific therapeutic interventions for this deleterious complication in breast cancer. Here, two questions are addressed to study the mechanism of breast cancer metastasis to bone: (1) What makes bone a preferential target site of metastasis? (2) What makes breast cancer able to colonize bone? (3) An animal model in which intracardiac inoculation of breast cancer cells selectively causes osteolytic bone metastases was developed. Experimental results obtained using this unique in-vivo model of bone metastasis are described and discussed.', 'authors': [{'lastname': 'Yoneda', 'forename': 'T', 'initials': 'T', 'identifier': '', 'affiliation': 'Department of Biochemistry, Osaka University Faculty of Dentistry, 1-8 Yamada-oka, Suita, Osaka 565-0891, Japan.'}], 'journal': 'Journal of orthopaedic science : official journal of the Japanese Orthopaedic Association', 'pubdate': '2000'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '15774130', '_score': 17.297037, '_source': {'pmid': '32391946', 'auto_id': 15774130, 'text': 'Why do young people get cancer? Oncologists and cancer biologists are frequently confronted by the question of what causes cancer? This is particularly vexing for cancers affecting children and young adults who have had limited exposure to environmental mutagens and the effects of aging. Here, I focus on a general framework of the causes of early-onset cancer development in children and young adults by relating inherited and constitutional cancer predisposition, oncogenic pathogens, and developmental mutations. This framework has implications not only for mechanistic investigation of young cancers, but should also clarify improved strategies for their treatment, screening, and potential prevention.', 'full_text': 'Why do young people get cancer?\\n\\nOncologists and cancer biologists are frequently confronted by the question of what causes cancer? This is particularly vexing for cancers affecting children and young adults who have had limited exposure to environmental mutagens and the effects of aging. Here, I focus on a general framework of the causes of early-onset cancer development in children and young adults by relating inherited and constitutional cancer predisposition, oncogenic pathogens, and developmental mutations. This framework has implications not only for mechanistic investigation of young cancers, but should also clarify improved strategies for their treatment, screening, and potential prevention.', 'authors': [{'lastname': 'Kentsis', 'forename': 'Alex', 'initials': 'A', 'identifier': '0000-0002-8063-9191', 'affiliation': 'Sloan Kettering Institute and Department of Pediatrics, Weill Medical College of Cornell University and Memorial Sloan Kettering Cancer Center, New York, New York.'}], 'journal': 'Pediatric blood & cancer', 'pubdate': '2020-07'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '5573064', '_score': 17.178644, '_source': {'pmid': '20207672', 'auto_id': 5573064, 'text': \"Answering patient questions about the role lifestyle factors play in cancer onset and recurrence: what do health care professionals say? This qualitative study examined how cancer specialists answer patient questions about what might have caused their cancer. Findings showed that while they were often candid about the role of smoking and drinking in cancer onset and that of diet in cancer recurrence, body weight and exercise were rarely mentioned. Any reluctance to discuss the role of lifestyle factors in cancer onset and recurrence arose from a desire to minimize patient distress, limitations in specialists' knowledge of the causes of cancer and perceived inadequacy of the available causal explanations when risk factors are multiple and probabilistic.\", 'full_text': \"Answering patient questions about the role lifestyle factors play in cancer onset and recurrence: what do health care professionals say?\\n\\nThis qualitative study examined how cancer specialists answer patient questions about what might have caused their cancer. Findings showed that while they were often candid about the role of smoking and drinking in cancer onset and that of diet in cancer recurrence, body weight and exercise were rarely mentioned. Any reluctance to discuss the role of lifestyle factors in cancer onset and recurrence arose from a desire to minimize patient distress, limitations in specialists' knowledge of the causes of cancer and perceived inadequacy of the available causal explanations when risk factors are multiple and probabilistic.\", 'authors': [{'lastname': 'Miles', 'forename': 'Anne', 'initials': 'A', 'identifier': '', 'affiliation': 'Department of Epidemiology and Public Health, University College London, London WC1E 6BT, UK. a.miles@ucl.ac.uk'}, {'lastname': 'Simon', 'forename': 'Alice', 'initials': 'A', 'identifier': '', 'affiliation': ''}, {'lastname': 'Wardle', 'forename': 'Jane', 'initials': 'J', 'identifier': '', 'affiliation': ''}], 'journal': 'Journal of health psychology', 'pubdate': '2010-03'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '16687968', '_score': 17.162868, '_source': {'pmid': '33369797', 'auto_id': 16687968, 'text': 'Bone metastases induce metabolic changes and mitophagy in mice. NEW FINDINGS What is the central question of this study? Cachexia causes severe changes in skeletal muscle metabolism and function and is a key predictor of negative outcomes in cancer patients: what are the changes in whole animal energy metabolism and mitochondria in skeletal muscle? What is the main finding and its importance? There is decreased whole animal energy expenditure in mice with cachexia. They displayed highly dysmorphic mitochondria and mitophagy in skeletal muscle. ABSTRACT Cachexia causes changes in skeletal muscle metabolism. Mice with MDA-MB-231 breast cancer bone metastases and cachexia have decreased whole animal energy metabolism and increased skeletal muscle mitophagy. We examined whole animal energy metabolism by indirect calorimetry in mice with MDA-MB-231 breast cancer bone metastases, and showed decreased energy expenditure. We also examined skeletal muscle mitochondria and found that mitochondria in mice with MDA-MB-231 bone metastases are highly dysmorphic and have altered protein markers of mitochondrial biogenesis and dynamics. In addition, LC3B protein was increased in mitochondria of skeletal muscle from cachectic mice, and colocalized with the mitochondrial protein Tom20. Our data demonstrate the importance of mitophagy in cachexia. Understanding these changes will help contribute to defining treatments for cancer cachexia.', 'full_text': 'Bone metastases induce metabolic changes and mitophagy in mice.\\n\\nNEW FINDINGS\\nWhat is the central question of this study? Cachexia causes severe changes in skeletal muscle metabolism and function and is a key predictor of negative outcomes in cancer patients: what are the changes in whole animal energy metabolism and mitochondria in skeletal muscle? What is the main finding and its importance? There is decreased whole animal energy expenditure in mice with cachexia. They displayed highly dysmorphic mitochondria and mitophagy in skeletal muscle.\\n\\n\\nABSTRACT\\nCachexia causes changes in skeletal muscle metabolism. Mice with MDA-MB-231 breast cancer bone metastases and cachexia have decreased whole animal energy metabolism and increased skeletal muscle mitophagy. We examined whole animal energy metabolism by indirect calorimetry in mice with MDA-MB-231 breast cancer bone metastases, and showed decreased energy expenditure. We also examined skeletal muscle mitochondria and found that mitochondria in mice with MDA-MB-231 bone metastases are highly dysmorphic and have altered protein markers of mitochondrial biogenesis and dynamics. In addition, LC3B protein was increased in mitochondria of skeletal muscle from cachectic mice, and colocalized with the mitochondrial protein Tom20. Our data demonstrate the importance of mitophagy in cachexia. Understanding these changes will help contribute to defining treatments for cancer cachexia.', 'authors': [{'lastname': 'Wilcox-Hagerty', 'forename': 'Jenna', 'initials': 'J', 'identifier': '', 'affiliation': 'The Penn State College of Medicine, Department of Cellular and Molecular Physiology, Hershey, PA, USA.'}, {'lastname': 'Xu', 'forename': 'Haifang', 'initials': 'H', 'identifier': '', 'affiliation': 'The Penn State College of Medicine, Department of Cellular and Molecular Physiology, Hershey, PA, USA.'}, {'lastname': 'Hain', 'forename': 'Brian A', 'initials': 'BA', 'identifier': '', 'affiliation': 'The Penn State College of Medicine, Department of Cellular and Molecular Physiology, Hershey, PA, USA.'}, {'lastname': 'Arnold', 'forename': 'Amy C', 'initials': 'AC', 'identifier': '', 'affiliation': 'The Penn State College of Medicine, Department of Neural and Behavioral Sciences, Hershey, PA, USA.'}, {'lastname': 'Waning', 'forename': 'David L', 'initials': 'DL', 'identifier': '0000-0002-3858-7623', 'affiliation': 'The Penn State College of Medicine, Department of Cellular and Molecular Physiology, Hershey, PA, USA.'}], 'journal': 'Experimental physiology', 'pubdate': '2021-02'}}, {'_index': 'medline-faiss-hnsw-lexical', '_id': '12915066', '_score': 17.037426, '_source': {'pmid': '29219713', 'auto_id': 12915066, 'text': 'Liver transplantation. Preview How many months of documented abstinence are required before a patient with alcoholic cirrhosis can be considered for liver transplantation? What is the role of liver transplantation as treatment for primary hepatocellular cancer? What are the possible causes of elevated liver enzyme levels following transplantation? Which patients with neurologic injury are potential organ donors? The authors answer these and other questions primary care physicians may have about this lifesaving procedure.', 'full_text': 'Liver transplantation.\\n\\nPreview How many months of documented abstinence are required before a patient with alcoholic cirrhosis can be considered for liver transplantation? What is the role of liver transplantation as treatment for primary hepatocellular cancer? What are the possible causes of elevated liver enzyme levels following transplantation? Which patients with neurologic injury are potential organ donors? The authors answer these and other questions primary care physicians may have about this lifesaving procedure.', 'authors': [{'lastname': 'Gholson', 'forename': 'Charles F', 'initials': 'CF', 'identifier': '', 'affiliation': ''}, {'lastname': 'McDonald', 'forename': 'John', 'initials': 'J', 'identifier': '', 'affiliation': ''}, {'lastname': 'McMillan', 'forename': 'Robert', 'initials': 'R', 'identifier': '', 'affiliation': ''}], 'journal': 'Postgraduate medicine', 'pubdate': '1995-02'}}]}}\n"
     ]
    }
   ],
   "source": [
    "query_body = {\n",
    "    \"size\": 10,\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": \"What are the Cancer Causes\",\n",
    "            \"fields\": [\"text\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the query\n",
    "response = client_lexical.search(\n",
    "    index=\"medline-faiss-hnsw-lexical\",\n",
    "    body=query_body\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from qdrant_client.http.models import PointStruct\n",
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "# 3.145.52.195\n",
    "verifai_ip='3.23.103.76'\n",
    "qdrant_port=6333\n",
    "TIMEOUT=60\n",
    "url = f\"https://{verifai_ip}:{qdrant_port}\"\n",
    "qdrant_api=\"8da7725d78141e19a9bf3d878f4cb333fedb56eed9727904b46ce4b32e1ce085\"\n",
    "client_semantic = QdrantClient(url=url, api_key=qdrant_api, timeout=TIMEOUT, https=True,**{'verify': False})\n",
    "#client_semantic = QdrantClient(host, port=6333, timeout = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the type of lexical indexing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_pmid = False\n",
    "\n",
    "if lexical_pmid:\n",
    "    index_name_lexical = 'medline-faiss-hnsw-lexical-pmid'\n",
    "else:\n",
    "    index_name_lexical ='medline-faiss-hnsw-lexical'\n",
    "\n",
    "coll_name_semantic = \"medline-faiss-hnsw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Adela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Adela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Ensure that the necessary NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, index_lexical:str = \"medline-faiss-hnsw-lexical\",lexical_pmid = False, index_name_semantic =\"medline-faiss-hnsw\", rescore = False, model=None, lexical_client=None, semantic_client=None, output_file_path=\"queries/queries.tsv\", stopwords=set([])):\n",
    "        self.index_lexical_name = index_lexical\n",
    "        self.index_name_semantic = index_name_semantic\n",
    "        # 2 index name (?)\n",
    "        self.model = model\n",
    "        #self.lexical_pmid = lexical_pmid\n",
    "        self.lexical_client = lexical_client\n",
    "        self.semantic_client = semantic_client\n",
    "        self.output_file_path = output_file_path\n",
    "        self.stop_words = stopwords\n",
    "        self.query_result = []\n",
    "        self.rescore = rescore\n",
    "        self.lexical_query = self.lexical_query_pmid if lexical_pmid else self.lexical_query\n",
    "    \n",
    "    def set_rescore(self, rescore):\n",
    "        self.rescore = rescore\n",
    "\n",
    "    def preprocess_query(self, query_str):\n",
    "        return ' '.join([word for word in word_tokenize(query_str) if word.lower() not in self.stop_words])\n",
    "\n",
    "    def save_results(self):\n",
    "        with open(self.output_file_path, \"w\") as file:\n",
    "            json.dump(self.query_result, file, indent=4)\n",
    "      \n",
    "    \n",
    "    def reorder_pmid(self, retrived_documents):\n",
    "        pmid_scores = {}\n",
    "        \n",
    "        # Iterate through the set data\n",
    "        for _, value in retrived_documents.items():\n",
    "            pmid = value['pmid']\n",
    "            score = value['score']\n",
    "            \n",
    "            # Check if pmid already exists in the dictionary\n",
    "            if pmid in pmid_scores:\n",
    "                pmid_scores[pmid] += score\n",
    "            else:\n",
    "                pmid_scores[pmid] = score\n",
    "           \n",
    "        return pmid_scores\n",
    "    \n",
    "    def lexical_query(self, query_str, limit=10):\n",
    "        if self.lexical_client == None:\n",
    "            raise ValueError(\"No Lexical client defined\")\n",
    "        \n",
    "        query = {\n",
    "                \"size\": limit,\n",
    "                \"query\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query_str,\n",
    "                        \"fields\": [\"text\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "       \n",
    "        results = self.lexical_client.search(index=self.index_lexical_name, body=query) \n",
    "        retrived_documents = {}\n",
    "        max_score = results['hits']['max_score']\n",
    "     \n",
    "        for hit in results[\"hits\"][\"hits\"]:\n",
    "            \n",
    "            pmid = hit[\"_source\"][\"pmid\"]\n",
    "            score = hit[\"_score\"]\n",
    "            auto_id = hit[\"_id\"]\n",
    "            \n",
    "            \n",
    "            \n",
    "            retrived_documents[auto_id] = {\n",
    "                \"score\": round(score/max_score, 5),\n",
    "                \"pmid\": pmid\n",
    "                }\n",
    "        \n",
    "        retrived_documents = self.reorder_pmid(retrived_documents)\n",
    "        return retrived_documents #adjust the return \n",
    "    \n",
    "    def lexical_query_pmid(self, query_str, limit=10):\n",
    "        #print(\"Lexical = \",query_str)\n",
    "        if self.lexical_client == None:\n",
    "            raise ValueError(\"No Lexical client defined\")\n",
    "        \n",
    "        query = {\n",
    "                \"size\": limit,\n",
    "                \"query\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query_str,\n",
    "                        \"fields\": [\"full_text\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        results = self.lexical_client.search(index=self.index_lexical_name, body=query) \n",
    "        \n",
    "        retrieved_documents = {}\n",
    "        max_score = results['hits']['max_score']\n",
    "        for hit in results[\"hits\"][\"hits\"]:\n",
    "            \n",
    "            pmid = hit[\"_source\"][\"pmid\"]\n",
    "            score = hit[\"_score\"] / max_score\n",
    "            \n",
    "            retrieved_documents[pmid] = score\n",
    "            \n",
    "        return retrieved_documents #adjust the return \n",
    "\n",
    "    def semantic_query(self, query, limit=10):\n",
    "        #print(\"semantic = \",query)\n",
    "        if self.semantic_client == None:\n",
    "            raise ValueError(\"No Semantic client defined\")\n",
    "        if self.model == None:\n",
    "            raise ValueError(\"No model defined\")\n",
    "        \n",
    "        query_vector = self.model.encode(query).tolist()\n",
    "    \n",
    "        search_params=models.SearchParams(\n",
    "            quantization=models.QuantizationSearchParams(rescore=self.rescore)\n",
    "            )\n",
    "        results = self.semantic_client.search(collection_name=self.index_name_semantic,query_vector=query_vector,search_params=search_params, limit=limit)\n",
    "    \n",
    "        #results = self.semantic_client.search(collection_name=self.index_name_semantic,query_vector=query_vector, limit=limit)\n",
    "        \n",
    "        retrived_documents = {}\n",
    "        max_score = None\n",
    "        for i,document in enumerate(results):\n",
    "            \n",
    "            pmid = document.payload['pmid']\n",
    "            score = document.score\n",
    "            if i == 0:\n",
    "                # first score is the max\n",
    "                max_score = score\n",
    "            retrived_documents[document.id] = { 'pmid': pmid, 'score': round(score / max_score, 5) } \n",
    "\n",
    "        retrived_documents = self.reorder_pmid(retrived_documents)\n",
    "        \n",
    "        return retrived_documents\n",
    "    \n",
    "\n",
    "    def hybrid_query(self, query_lexical, query_semantic, lex_parameter = 0.5, semantic_parameter = 0.5, limit=10):\n",
    "        if (lex_parameter + semantic_parameter) > 1:\n",
    "            raise ValueError(\"Uncorrect parameters for Hybrid Queries\")\n",
    "        lexical_results = self.lexical_query(query_lexical, limit = limit) \n",
    "        semantic_results = self.semantic_query(query_semantic, limit)\n",
    "        max_score = 0\n",
    "        retrived_documents = {}\n",
    "        \n",
    "        for lex_pmid in lexical_results:\n",
    "            score = lexical_results[lex_pmid] * lex_parameter\n",
    "            if lex_pmid in semantic_results:\n",
    "                score += semantic_results[lex_pmid] * semantic_parameter\n",
    "\n",
    "            retrived_documents[lex_pmid] = score\n",
    "            max_score = max(max_score, score)\n",
    "            \n",
    "\n",
    "        for semantic_pmid in semantic_results:\n",
    "            if semantic_pmid not in lexical_results:\n",
    "                score = semantic_results[semantic_pmid] * semantic_parameter\n",
    "                retrived_documents[semantic_pmid] = score\n",
    "                max_score = max(max_score, score)\n",
    "                \n",
    "        return retrived_documents # just to have a starting point\n",
    "\n",
    "\n",
    "    def execute_query(self, query_str, query_type='lexical', lex_parameter = 0.5, semantic_parameter = 0.5,limit = 10,save = True, stopwords_preprocessing=True):\n",
    "        #print(\"Before = \",query_str)\n",
    "        text_query = self.preprocess_query(query_str) if stopwords_preprocessing else query_str\n",
    "        \n",
    "        if query_type == 'lexical':\n",
    "            results = self.lexical_query(text_query, limit=limit) \n",
    "        \n",
    "        elif query_type == 'semantic':\n",
    "            results = self.semantic_query(query_str, limit=limit)\n",
    "\n",
    "        elif query_type == 'hybrid':\n",
    "            results = self.hybrid_query(text_query, query_str, lex_parameter, semantic_parameter, limit=limit)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid query type specified. Choose 'lexical', 'semantic', or 'hybrid'.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        document_retrived = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "        document_retrived = document_retrived[:limit+1] # in the hybrid search we can return more documents\n",
    "        #print(\"Results \", document_retrived)\n",
    "        if save:\n",
    "            self.process_results(document_retrived, query_str, query_type)\n",
    "\n",
    "        return document_retrived\n",
    "    \n",
    "    # needs to be rewrited\n",
    "    def process_results(self, results, query_str,query_type):\n",
    "        \n",
    "        retrieved_documents = []\n",
    "        for element in results:\n",
    "            \n",
    "            pmid,_ = element\n",
    "            query = {\n",
    "                    \"query\": {\n",
    "                        \"term\": {\n",
    "                        \"pmid\": int(pmid)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            results = self.lexical_client.search(index=self.index_lexical_name, body=query) \n",
    "            full_text = results['hits']['hits'][0][\"_source\"]['full_text']\n",
    "            pmid = results['hits']['hits'][0][\"_source\"]['pmid']\n",
    "\n",
    "            retrieved_documents.append({\n",
    "                \"pmid\": pmid,\n",
    "                \"text\": full_text\n",
    "            })\n",
    "\n",
    "        dict_to_save = {'query': query_str, 'query_type': query_type, 'abstracts' : retrieved_documents}\n",
    "        self.query_result.append(dict_to_save)  \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_parser = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10797929', 0.5),\n",
       " ('15877281', 0.5),\n",
       " ('37560515', 0.49687),\n",
       " ('29597095', 0.494725),\n",
       " ('20870045', 0.49326),\n",
       " ('29922639', 0.49277),\n",
       " ('9462748', 0.490925),\n",
       " ('22303795', 0.49066),\n",
       " ('24914010', 0.490565),\n",
       " ('19332160', 0.49053),\n",
       " ('22106036', 0.49053)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_parser.execute_query(query_str=\"Which gene is responsible for disfunction in speech for children?\", query_type='hybrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the evaluation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5049\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "evaluation_file = 'training12b_new.json'\n",
    "\n",
    "with open(evaluation_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(len(data['questions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def clean_documents(documents):\n",
    "    #output_documents = set()\n",
    "    output_documents = []  # Changed previous set to list\n",
    "    for doc in documents:\n",
    "        output_documents.append((doc.replace(\"http://www.ncbi.nlm.nih.gov/pubmed/\",\"\")))\n",
    "    return output_documents\n",
    "\n",
    "def average_precision(retrived_doc, true_doc):\n",
    "    # Initialize variables\n",
    "    precision_sum = 0\n",
    "    num_retrieved_docs = 0\n",
    "    \n",
    "    # Calculate precision at each relevant document position\n",
    "    for i, retrived in enumerate(retrived_doc, start=1):\n",
    "        pmid,_ = retrived\n",
    "        if pmid in true_doc:  # Check if the document is relevant\n",
    "            num_retrieved_docs += 1\n",
    "            precision_sum += num_retrieved_docs / i  # Calculate precision at cutoff i\n",
    "\n",
    "    # Calculate average precision\n",
    "    if num_retrieved_docs == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return precision_sum / num_retrieved_docs\n",
    "\n",
    "\n",
    "def evaluation(query_parser, data, query_type,alpha=0.5, beta=0.5, stopwords_preprocessing = False, path = \"query_result.json\"):\n",
    "    avg_precisions_sum = [] # sum all average precision and divide with number of queries \n",
    "    precisions_sum = []\n",
    "    queries_time = []\n",
    "    for i,question in enumerate(data['questions']):\n",
    "        dict_to_save = {}\n",
    "        query = question['body']\n",
    "        dict_to_save['query'] = query\n",
    "        dict_to_save['query_type'] = query_type\n",
    "        relevant_documents = clean_documents(question['documents'])\n",
    "        start_time = time.time()\n",
    "        results = query_parser.execute_query(query,query_type = query_type, lex_parameter = alpha, semantic_parameter = beta,limit = len(relevant_documents), save=False, stopwords_preprocessing = stopwords_preprocessing)\n",
    "        queries_time.append(time.time() - start_time)\n",
    "        \n",
    "        #results = [('20598273',1), ('4',1), ('6650562',1), ('2',1),('21995290',1),('15617541',1),('23001136',1),('8896569',1), ('12239580',1)]\n",
    "        dict_to_save['true_documents'] = relevant_documents  ##Conversion to list removed\n",
    "        dict_to_save['retrieved_documents'] = results\n",
    "       \n",
    "\n",
    "    \n",
    "        number_retrieved_documents = 0\n",
    "        for pmid,_ in results:\n",
    "            if pmid in relevant_documents:\n",
    "                number_retrieved_documents +=1\n",
    "\n",
    "        precision = number_retrieved_documents / len(relevant_documents)\n",
    "        recall = number_retrieved_documents / len(relevant_documents)\n",
    "        avg_precision = average_precision(results, relevant_documents)\n",
    "        \n",
    "        precisions_sum.append(precision)\n",
    "        #recalls.append(recall)\n",
    "        \n",
    "        avg_precisions_sum.append(avg_precision)\n",
    "        \n",
    "        dict_to_save['precision'] = precision\n",
    "        #dict_to_save['recall'] = recall\n",
    "        dict_to_save['avg_precision'] = avg_precision\n",
    "        with open(path, 'a') as output_file:\n",
    "            output_file.write(json.dumps(dict_to_save) + '\\n')\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f\"Analyzed {i+1} queries\")\n",
    "            print(\"Actual Results...\")\n",
    "            print(f\"Mean precision = {np.mean(precisions_sum):.3f}\")\n",
    "            #print(f\"Mean recall = {np.mean(recalls):.3f}\")\n",
    "            print(f\"Mean Average Precision = {np.mean(avg_precisions_sum):.3f}\")\n",
    "            print(f\"Mean Time needed to execute a query = {np.mean(queries_time):.3f}\")\n",
    "    print(\"FINAL RESULTS \")\n",
    "    print(f\"Mean precision = {np.mean(precisions_sum):.3f}\")\n",
    "    #print(f\"Mean recall = {np.mean(recalls):.3f}\")\n",
    "    print(f\"Mean Average Precision = {np.mean(avg_precisions_sum):.3f}\")\n",
    "    print(f\"Mean Time needed to execute a query = {np.mean(queries_time):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Lexical Auto-id Stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.222\n",
      "Mean Average Precision = 0.386\n",
      "Mean Time needed to execute a query = 0.211\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.231\n",
      "Mean Average Precision = 0.382\n",
      "Mean Time needed to execute a query = 0.207\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.228\n",
      "Mean Average Precision = 0.374\n",
      "Mean Time needed to execute a query = 0.207\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.241\n",
      "Mean Average Precision = 0.384\n",
      "Mean Time needed to execute a query = 0.205\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.263\n",
      "Mean Average Precision = 0.403\n",
      "Mean Time needed to execute a query = 0.202\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.266\n",
      "Mean Average Precision = 0.396\n",
      "Mean Time needed to execute a query = 0.200\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.271\n",
      "Mean Average Precision = 0.395\n",
      "Mean Time needed to execute a query = 0.198\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.276\n",
      "Mean Average Precision = 0.400\n",
      "Mean Time needed to execute a query = 0.197\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.282\n",
      "Mean Average Precision = 0.403\n",
      "Mean Time needed to execute a query = 0.197\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.280\n",
      "Mean Average Precision = 0.401\n",
      "Mean Time needed to execute a query = 0.197\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.280\n",
      "Mean Average Precision = 0.402\n",
      "Mean Time needed to execute a query = 0.197\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser,data, query_type=\"lexical\", path = \"Eval_results_BioASQ_all/lexical_results.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Lexical Pmid Stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "query_parser_pmid = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=True, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.224\n",
      "Mean Average Precision = 0.393\n",
      "Mean Time needed to execute a query = 0.205\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.234\n",
      "Mean Average Precision = 0.389\n",
      "Mean Time needed to execute a query = 0.202\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.232\n",
      "Mean Average Precision = 0.379\n",
      "Mean Time needed to execute a query = 0.201\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.245\n",
      "Mean Average Precision = 0.390\n",
      "Mean Time needed to execute a query = 0.200\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.268\n",
      "Mean Average Precision = 0.408\n",
      "Mean Time needed to execute a query = 0.197\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.271\n",
      "Mean Average Precision = 0.401\n",
      "Mean Time needed to execute a query = 0.195\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.275\n",
      "Mean Average Precision = 0.399\n",
      "Mean Time needed to execute a query = 0.684\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.280\n",
      "Mean Average Precision = 0.403\n",
      "Mean Time needed to execute a query = 0.622\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.286\n",
      "Mean Average Precision = 0.407\n",
      "Mean Time needed to execute a query = 0.574\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.285\n",
      "Mean Average Precision = 0.406\n",
      "Mean Time needed to execute a query = 0.536\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.285\n",
      "Mean Average Precision = 0.406\n",
      "Mean Time needed to execute a query = 0.533\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser_pmid,data, query_type=\"lexical\", path = \"Eval_results_BioASQ_all/lexical_results_pmid.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result lexical pmid with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not', 'so', 'over', 'when', 'where', 'myself', 'yourself', 'doesn', 'wasn', 'themselves', 'only', 'than', 'after', 'himself', 'theirs', 'no', 's', 'his', 'should', 'hadn', 'shouldn', \"you'll\", 'off', 'hasn', 'has', 've', 'mustn', 'will', 'herself', 'am', 'me', 'into', 'don', 'and', 'll', 'up', 'any', 't', 'your', 'that', 'then', \"couldn't\", 'him', 'be', 'doing', 'he', 'from', \"it's\", 're', 'some', 'didn', \"haven't\", 'before', \"shouldn't\", \"aren't\", \"shan't\", 'them', 'having', 'these', \"you'd\", \"she's\", 'while', 'on', 'very', 'between', 'all', 'ourselves', \"isn't\", \"you're\", 'other', 'aren', 'is', 'ma', 'under', 'being', \"wasn't\", 'this', \"won't\", 'haven', 'my', 'most', 'own', \"don't\", \"needn't\", 'further', 'isn', 'which', 'wouldn', 'each', \"didn't\", 'm', 'by', 'just', 'in', 'won', 'been', 'because', 'below', 'but', 'whom', 'what', 'those', 'out', 'for', \"wouldn't\", 'both', 'through', 'her', \"doesn't\", 'during', 'their', 'few', 'shan', 'ain', \"hasn't\", 'why', 'too', 'itself', \"that'll\", 'she', 'i', 'they', 'with', \"should've\", 'at', 'against', 'the', 'couldn', 'yourselves', 'there', 'were', \"weren't\", 'of', 'an', \"hadn't\", \"mustn't\", 'was', 'until', 'you', 'needn', 'had', 'once', 'same', 'hers', 'who', 'does', 'more', 'such', 'ours', \"you've\", 'did', \"mightn't\", 'd', 'how', 'y', 'as', 'yours', 'can', 'about', 'above', 'it', 'are', 'have', 'o', 'weren', 'do', 'now', 'nor', 'mightn', 'if', 'down', 'its', 'to', 'again', 'here', 'a', 'we', 'or', 'our'}\n"
     ]
    }
   ],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "print(english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.234\n",
      "Mean Average Precision = 0.412\n",
      "Mean Time needed to execute a query = 0.171\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.240\n",
      "Mean Average Precision = 0.399\n",
      "Mean Time needed to execute a query = 0.170\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.239\n",
      "Mean Average Precision = 0.391\n",
      "Mean Time needed to execute a query = 0.170\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.250\n",
      "Mean Average Precision = 0.399\n",
      "Mean Time needed to execute a query = 0.170\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.271\n",
      "Mean Average Precision = 0.416\n",
      "Mean Time needed to execute a query = 0.169\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.274\n",
      "Mean Average Precision = 0.409\n",
      "Mean Time needed to execute a query = 0.168\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.277\n",
      "Mean Average Precision = 0.405\n",
      "Mean Time needed to execute a query = 0.167\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.282\n",
      "Mean Average Precision = 0.409\n",
      "Mean Time needed to execute a query = 0.167\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.288\n",
      "Mean Average Precision = 0.412\n",
      "Mean Time needed to execute a query = 0.166\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.286\n",
      "Mean Average Precision = 0.410\n",
      "Mean Time needed to execute a query = 0.166\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.287\n",
      "Mean Average Precision = 0.411\n",
      "Mean Time needed to execute a query = 0.166\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser_stopwords,data, query_type=\"lexical\", path = \"Eval_results_BioASQ_all/lex_results_stopwords.json\",stopwords_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result lexical autoid stopword True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.228\n",
      "Mean Average Precision = 0.402\n",
      "Mean Time needed to execute a query = 0.176\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.235\n",
      "Mean Average Precision = 0.391\n",
      "Mean Time needed to execute a query = 0.174\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.234\n",
      "Mean Average Precision = 0.381\n",
      "Mean Time needed to execute a query = 0.174\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.245\n",
      "Mean Average Precision = 0.389\n",
      "Mean Time needed to execute a query = 0.173\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.267\n",
      "Mean Average Precision = 0.408\n",
      "Mean Time needed to execute a query = 0.172\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.270\n",
      "Mean Average Precision = 0.401\n",
      "Mean Time needed to execute a query = 0.171\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.274\n",
      "Mean Average Precision = 0.400\n",
      "Mean Time needed to execute a query = 0.170\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.279\n",
      "Mean Average Precision = 0.403\n",
      "Mean Time needed to execute a query = 0.169\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.284\n",
      "Mean Average Precision = 0.406\n",
      "Mean Time needed to execute a query = 0.169\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.281\n",
      "Mean Average Precision = 0.404\n",
      "Mean Time needed to execute a query = 0.169\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.282\n",
      "Mean Average Precision = 0.404\n",
      "Mean Time needed to execute a query = 0.169\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical\"\n",
    "lexical_pmid = False\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "evaluation(query_parser_stopwords,data, query_type=\"lexical\", path = \"Eval_results_BioASQ_all/lex_results_stopwords_auto_id.json\",stopwords_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Semantic without rescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.134\n",
      "Mean Average Precision = 0.276\n",
      "Mean Time needed to execute a query = 0.301\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.127\n",
      "Mean Average Precision = 0.265\n",
      "Mean Time needed to execute a query = 0.289\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.126\n",
      "Mean Average Precision = 0.262\n",
      "Mean Time needed to execute a query = 0.286\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.130\n",
      "Mean Average Precision = 0.268\n",
      "Mean Time needed to execute a query = 0.287\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.137\n",
      "Mean Average Precision = 0.272\n",
      "Mean Time needed to execute a query = 0.279\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.139\n",
      "Mean Average Precision = 0.266\n",
      "Mean Time needed to execute a query = 0.272\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.138\n",
      "Mean Average Precision = 0.259\n",
      "Mean Time needed to execute a query = 0.264\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.141\n",
      "Mean Average Precision = 0.259\n",
      "Mean Time needed to execute a query = 0.260\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.140\n",
      "Mean Average Precision = 0.256\n",
      "Mean Time needed to execute a query = 0.258\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.140\n",
      "Mean Average Precision = 0.256\n",
      "Mean Time needed to execute a query = 0.257\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.140\n",
      "Mean Average Precision = 0.257\n",
      "Mean Time needed to execute a query = 0.256\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser,data, query_type=\"semantic\", path = \"Eval_results_BioASQ_all/semantic_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Semantic with rescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.136\n",
      "Mean Average Precision = 0.283\n",
      "Mean Time needed to execute a query = 0.361\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.129\n",
      "Mean Average Precision = 0.268\n",
      "Mean Time needed to execute a query = 0.354\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.130\n",
      "Mean Average Precision = 0.266\n",
      "Mean Time needed to execute a query = 0.342\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.134\n",
      "Mean Average Precision = 0.274\n",
      "Mean Time needed to execute a query = 0.341\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.140\n",
      "Mean Average Precision = 0.277\n",
      "Mean Time needed to execute a query = 0.328\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.143\n",
      "Mean Average Precision = 0.271\n",
      "Mean Time needed to execute a query = 0.313\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.142\n",
      "Mean Average Precision = 0.263\n",
      "Mean Time needed to execute a query = 0.301\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.144\n",
      "Mean Average Precision = 0.264\n",
      "Mean Time needed to execute a query = 0.294\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.144\n",
      "Mean Average Precision = 0.260\n",
      "Mean Time needed to execute a query = 0.290\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.143\n",
      "Mean Average Precision = 0.260\n",
      "Mean Time needed to execute a query = 0.289\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.144\n",
      "Mean Average Precision = 0.261\n",
      "Mean Time needed to execute a query = 0.289\n"
     ]
    }
   ],
   "source": [
    "query_parser.set_rescore(True)\n",
    "evaluation(query_parser,data, query_type=\"semantic\", path = \"Eval_results_BioASQ_all/semantic_results.json\")\n",
    "query_parser.set_rescore(False) # re insert the rescore to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Hybrid with lexical autoid Stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.184\n",
      "Mean Average Precision = 0.388\n",
      "Mean Time needed to execute a query = 0.656\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.181\n",
      "Mean Average Precision = 0.382\n",
      "Mean Time needed to execute a query = 0.630\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.180\n",
      "Mean Average Precision = 0.370\n",
      "Mean Time needed to execute a query = 0.621\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.190\n",
      "Mean Average Precision = 0.382\n",
      "Mean Time needed to execute a query = 0.605\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.212\n",
      "Mean Average Precision = 0.398\n",
      "Mean Time needed to execute a query = 0.588\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.221\n",
      "Mean Average Precision = 0.396\n",
      "Mean Time needed to execute a query = 0.565\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.230\n",
      "Mean Average Precision = 0.395\n",
      "Mean Time needed to execute a query = 0.546\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.239\n",
      "Mean Average Precision = 0.401\n",
      "Mean Time needed to execute a query = 0.536\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.244\n",
      "Mean Average Precision = 0.404\n",
      "Mean Time needed to execute a query = 0.529\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.245\n",
      "Mean Average Precision = 0.404\n",
      "Mean Time needed to execute a query = 0.528\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.246\n",
      "Mean Average Precision = 0.404\n",
      "Mean Time needed to execute a query = 0.527\n"
     ]
    }
   ],
   "source": [
    "evaluation(query_parser, data, query_type=\"hybrid\", path = \"Eval_results_BioASQ_all/hybrid_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Hybrid with lexical pmid Stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evaluation(query_parser_pmid, data, query_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m\"\u001b[39m, path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval_results_BioASQ_all/hybrid_results_pmid.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[28], line 41\u001b[0m, in \u001b[0;36mevaluation\u001b[1;34m(query_parser, data, query_type, alpha, beta, stopwords_preprocessing, path)\u001b[0m\n\u001b[0;32m     39\u001b[0m relevant_documents \u001b[38;5;241m=\u001b[39m clean_documents(question[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     40\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 41\u001b[0m results \u001b[38;5;241m=\u001b[39m query_parser\u001b[38;5;241m.\u001b[39mexecute_query(query,query_type \u001b[38;5;241m=\u001b[39m query_type, lex_parameter \u001b[38;5;241m=\u001b[39m alpha, semantic_parameter \u001b[38;5;241m=\u001b[39m beta,limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(relevant_documents), save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stopwords_preprocessing \u001b[38;5;241m=\u001b[39m stopwords_preprocessing)\n\u001b[0;32m     42\u001b[0m queries_time\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#results = [('20598273',1), ('4',1), ('6650562',1), ('2',1),('21995290',1),('15617541',1),('23001136',1),('8896569',1), ('12239580',1)]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 187\u001b[0m, in \u001b[0;36mQueryProcessor.execute_query\u001b[1;34m(self, query_str, query_type, lex_parameter, semantic_parameter, limit, save, stopwords_preprocessing)\u001b[0m\n\u001b[0;32m    184\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_query(query_str, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 187\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhybrid_query(text_query, query_str, lex_parameter, semantic_parameter, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid query type specified. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlexical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 154\u001b[0m, in \u001b[0;36mQueryProcessor.hybrid_query\u001b[1;34m(self, query_lexical, query_semantic, lex_parameter, semantic_parameter, limit)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncorrect parameters for Hybrid Queries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m lexical_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexical_query(query_lexical, limit \u001b[38;5;241m=\u001b[39m limit) \n\u001b[1;32m--> 154\u001b[0m semantic_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_query(query_semantic, limit)\n\u001b[0;32m    155\u001b[0m max_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    156\u001b[0m retrived_documents \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[23], line 130\u001b[0m, in \u001b[0;36mQueryProcessor.semantic_query\u001b[1;34m(self, query, limit)\u001b[0m\n\u001b[0;32m    125\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode(query)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    127\u001b[0m search_params\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSearchParams(\n\u001b[0;32m    128\u001b[0m     quantization\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mQuantizationSearchParams(rescore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescore)\n\u001b[0;32m    129\u001b[0m     )\n\u001b[1;32m--> 130\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_client\u001b[38;5;241m.\u001b[39msearch(collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_name_semantic,query_vector\u001b[38;5;241m=\u001b[39mquery_vector,search_params\u001b[38;5;241m=\u001b[39msearch_params, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#results = self.semantic_client.search(collection_name=self.index_name_semantic,query_vector=query_vector, limit=limit)\u001b[39;00m\n\u001b[0;32m    134\u001b[0m retrived_documents \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\qdrant_client.py:387\u001b[0m, in \u001b[0;36mQdrantClient.search\u001b[1;34m(self, collection_name, query_vector, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, append_payload, consistency, shard_key_selector, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search for closest vectors in collection taking into account filtering conditions\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    List of found close points with similarity scores.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m    388\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    389\u001b[0m     query_vector\u001b[38;5;241m=\u001b[39mquery_vector,\n\u001b[0;32m    390\u001b[0m     query_filter\u001b[38;5;241m=\u001b[39mquery_filter,\n\u001b[0;32m    391\u001b[0m     search_params\u001b[38;5;241m=\u001b[39msearch_params,\n\u001b[0;32m    392\u001b[0m     limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m    393\u001b[0m     offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    394\u001b[0m     with_payload\u001b[38;5;241m=\u001b[39mwith_payload,\n\u001b[0;32m    395\u001b[0m     with_vectors\u001b[38;5;241m=\u001b[39mwith_vectors,\n\u001b[0;32m    396\u001b[0m     score_threshold\u001b[38;5;241m=\u001b[39mscore_threshold,\n\u001b[0;32m    397\u001b[0m     append_payload\u001b[38;5;241m=\u001b[39mappend_payload,\n\u001b[0;32m    398\u001b[0m     consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m    399\u001b[0m     shard_key_selector\u001b[38;5;241m=\u001b[39mshard_key_selector,\n\u001b[0;32m    400\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    402\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py:563\u001b[0m, in \u001b[0;36mQdrantRemote.search\u001b[1;34m(self, collection_name, query_vector, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, append_payload, consistency, shard_key_selector, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(with_payload, grpc\u001b[38;5;241m.\u001b[39mWithPayloadSelector):\n\u001b[0;32m    561\u001b[0m     with_payload \u001b[38;5;241m=\u001b[39m GrpcToRest\u001b[38;5;241m.\u001b[39mconvert_with_payload_selector(with_payload)\n\u001b[1;32m--> 563\u001b[0m search_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp\u001b[38;5;241m.\u001b[39mpoints_api\u001b[38;5;241m.\u001b[39msearch_points(\n\u001b[0;32m    564\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    565\u001b[0m     consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m    566\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    567\u001b[0m     search_request\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSearchRequest(\n\u001b[0;32m    568\u001b[0m         vector\u001b[38;5;241m=\u001b[39mquery_vector,\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mquery_filter,\n\u001b[0;32m    570\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m    571\u001b[0m         offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    572\u001b[0m         params\u001b[38;5;241m=\u001b[39msearch_params,\n\u001b[0;32m    573\u001b[0m         with_vector\u001b[38;5;241m=\u001b[39mwith_vectors,\n\u001b[0;32m    574\u001b[0m         with_payload\u001b[38;5;241m=\u001b[39mwith_payload,\n\u001b[0;32m    575\u001b[0m         score_threshold\u001b[38;5;241m=\u001b[39mscore_threshold,\n\u001b[0;32m    576\u001b[0m         shard_key\u001b[38;5;241m=\u001b[39mshard_key_selector,\n\u001b[0;32m    577\u001b[0m     ),\n\u001b[0;32m    578\u001b[0m )\n\u001b[0;32m    579\u001b[0m result: Optional[List[types\u001b[38;5;241m.\u001b[39mScoredPoint]] \u001b[38;5;241m=\u001b[39m search_result\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch returned None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:1616\u001b[0m, in \u001b[0;36mSyncPointsApi.search_points\u001b[1;34m(self, collection_name, consistency, timeout, search_request)\u001b[0m\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_points\u001b[39m(\n\u001b[0;32m   1607\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1608\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1611\u001b[0m     search_request: m\u001b[38;5;241m.\u001b[39mSearchRequest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1612\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m m\u001b[38;5;241m.\u001b[39mInlineResponse20016:\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03m    Retrieve closest points based on vector similarity and given filtering conditions\u001b[39;00m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_for_search_points(\n\u001b[0;32m   1617\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m   1618\u001b[0m         consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m   1619\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1620\u001b[0m         search_request\u001b[38;5;241m=\u001b[39msearch_request,\n\u001b[0;32m   1621\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:750\u001b[0m, in \u001b[0;36m_PointsApi._build_for_search_points\u001b[1;34m(self, collection_name, consistency, timeout, search_request)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[0;32m    749\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    751\u001b[0m     type_\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mInlineResponse20016,\n\u001b[0;32m    752\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    753\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/collections/\u001b[39m\u001b[38;5;132;01m{collection_name}\u001b[39;00m\u001b[38;5;124m/points/search\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    754\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    755\u001b[0m     path_params\u001b[38;5;241m=\u001b[39mpath_params,\n\u001b[0;32m    756\u001b[0m     params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m    757\u001b[0m     content\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    758\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:79\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     78\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbuild_request(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, type_)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:96\u001b[0m, in \u001b[0;36mApiClient.send\u001b[1;34m(self, request, type_)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, type_: Type[T]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m---> 96\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiddleware(request, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_inner)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m201\u001b[39m, \u001b[38;5;241m202\u001b[39m]:\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:205\u001b[0m, in \u001b[0;36mBaseMiddleware.__call__\u001b[1;34m(self, request, call_next)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, call_next: Send) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_next(request)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:106\u001b[0m, in \u001b[0;36mApiClient.send_inner\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:188\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optional_thread_lock:\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;66;03m# Assign incoming requests to available connections,\u001b[39;00m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;66;03m# closing or creating new connections as required.\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# Wait until this request has an assigned connection.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:248\u001b[0m, in \u001b[0;36mConnectionPool._assign_requests_to_connections\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mis_closed():\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;66;03m# log: \"removing closed connection\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connections\u001b[38;5;241m.\u001b[39mremove(connection)\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhas_expired():\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;66;03m# log: \"closing expired connection\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connections\u001b[38;5;241m.\u001b[39mremove(connection)\n\u001b[0;32m    251\u001b[0m     closing_connections\u001b[38;5;241m.\u001b[39mappend(connection)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:188\u001b[0m, in \u001b[0;36mHTTPConnection.has_expired\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed\n\u001b[1;32m--> 188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhas_expired()\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:290\u001b[0m, in \u001b[0;36mHTTP11Connection.has_expired\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m keepalive_expired \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expire_at \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m now \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expire_at\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m# If the HTTP connection is idle but the socket is readable, then the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# only valid state is that the socket is about to return b\"\", indicating\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# a server-initiated disconnect.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m server_disconnected \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m HTTPConnectionState\u001b[38;5;241m.\u001b[39mIDLE\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_readable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    291\u001b[0m )\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keepalive_expired \u001b[38;5;129;01mor\u001b[39;00m server_disconnected\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:181\u001b[0m, in \u001b[0;36mSyncStream.get_extra_info\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_readable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m is_socket_readable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_utils.py:32\u001b[0m, in \u001b[0;36mis_socket_readable\u001b[1;34m(sock)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# The implementation below was stolen from:\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# https://github.com/python-trio/trio/blob/20ee2b1b7376db637435d80e266212a35837ddcc/trio/_socket.py#L471-L478\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# See also: https://github.com/encode/httpcore/pull/193#issuecomment-703129316\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Use select.select on Windows, and when poll is unavailable and select.poll\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# everywhere else. (E.g. When eventlet is in use. See #327)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(select, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoll\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     31\u001b[0m ):  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     rready, _, _ \u001b[38;5;241m=\u001b[39m select\u001b[38;5;241m.\u001b[39mselect([sock_fd], [], [], \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(rready)\n\u001b[0;32m     34\u001b[0m p \u001b[38;5;241m=\u001b[39m select\u001b[38;5;241m.\u001b[39mpoll()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation(query_parser_pmid, data, query_type=\"hybrid\", path = \"Eval_results_BioASQ_all/hybrid_results_pmid.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid pmid with stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m lexical_pmid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      3\u001b[0m query_parser_stopwords \u001b[38;5;241m=\u001b[39m QueryProcessor(index_lexical\u001b[38;5;241m=\u001b[39mindex_name_lexical, lexical_pmid\u001b[38;5;241m=\u001b[39mlexical_pmid, index_name_semantic \u001b[38;5;241m=\u001b[39m coll_name_semantic, model\u001b[38;5;241m=\u001b[39m model, lexical_client\u001b[38;5;241m=\u001b[39mclient_lexical, semantic_client\u001b[38;5;241m=\u001b[39mclient_semantic, stopwords\u001b[38;5;241m=\u001b[39menglish_stopwords)\n\u001b[1;32m----> 4\u001b[0m evaluation(query_parser_stopwords, data, query_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m\"\u001b[39m,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval_results_BioASQ_all/hybrid_results_pmid_stopwords.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, stopwords_preprocessing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[28], line 41\u001b[0m, in \u001b[0;36mevaluation\u001b[1;34m(query_parser, data, query_type, alpha, beta, stopwords_preprocessing, path)\u001b[0m\n\u001b[0;32m     39\u001b[0m relevant_documents \u001b[38;5;241m=\u001b[39m clean_documents(question[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     40\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 41\u001b[0m results \u001b[38;5;241m=\u001b[39m query_parser\u001b[38;5;241m.\u001b[39mexecute_query(query,query_type \u001b[38;5;241m=\u001b[39m query_type, lex_parameter \u001b[38;5;241m=\u001b[39m alpha, semantic_parameter \u001b[38;5;241m=\u001b[39m beta,limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(relevant_documents), save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stopwords_preprocessing \u001b[38;5;241m=\u001b[39m stopwords_preprocessing)\n\u001b[0;32m     42\u001b[0m queries_time\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#results = [('20598273',1), ('4',1), ('6650562',1), ('2',1),('21995290',1),('15617541',1),('23001136',1),('8896569',1), ('12239580',1)]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 187\u001b[0m, in \u001b[0;36mQueryProcessor.execute_query\u001b[1;34m(self, query_str, query_type, lex_parameter, semantic_parameter, limit, save, stopwords_preprocessing)\u001b[0m\n\u001b[0;32m    184\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_query(query_str, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 187\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhybrid_query(text_query, query_str, lex_parameter, semantic_parameter, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid query type specified. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlexical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 154\u001b[0m, in \u001b[0;36mQueryProcessor.hybrid_query\u001b[1;34m(self, query_lexical, query_semantic, lex_parameter, semantic_parameter, limit)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncorrect parameters for Hybrid Queries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m lexical_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexical_query(query_lexical, limit \u001b[38;5;241m=\u001b[39m limit) \n\u001b[1;32m--> 154\u001b[0m semantic_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_query(query_semantic, limit)\n\u001b[0;32m    155\u001b[0m max_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    156\u001b[0m retrived_documents \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[23], line 130\u001b[0m, in \u001b[0;36mQueryProcessor.semantic_query\u001b[1;34m(self, query, limit)\u001b[0m\n\u001b[0;32m    125\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode(query)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    127\u001b[0m search_params\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSearchParams(\n\u001b[0;32m    128\u001b[0m     quantization\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mQuantizationSearchParams(rescore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescore)\n\u001b[0;32m    129\u001b[0m     )\n\u001b[1;32m--> 130\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_client\u001b[38;5;241m.\u001b[39msearch(collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_name_semantic,query_vector\u001b[38;5;241m=\u001b[39mquery_vector,search_params\u001b[38;5;241m=\u001b[39msearch_params, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#results = self.semantic_client.search(collection_name=self.index_name_semantic,query_vector=query_vector, limit=limit)\u001b[39;00m\n\u001b[0;32m    134\u001b[0m retrived_documents \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\qdrant_client.py:387\u001b[0m, in \u001b[0;36mQdrantClient.search\u001b[1;34m(self, collection_name, query_vector, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, append_payload, consistency, shard_key_selector, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search for closest vectors in collection taking into account filtering conditions\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    List of found close points with similarity scores.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m    388\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    389\u001b[0m     query_vector\u001b[38;5;241m=\u001b[39mquery_vector,\n\u001b[0;32m    390\u001b[0m     query_filter\u001b[38;5;241m=\u001b[39mquery_filter,\n\u001b[0;32m    391\u001b[0m     search_params\u001b[38;5;241m=\u001b[39msearch_params,\n\u001b[0;32m    392\u001b[0m     limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m    393\u001b[0m     offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    394\u001b[0m     with_payload\u001b[38;5;241m=\u001b[39mwith_payload,\n\u001b[0;32m    395\u001b[0m     with_vectors\u001b[38;5;241m=\u001b[39mwith_vectors,\n\u001b[0;32m    396\u001b[0m     score_threshold\u001b[38;5;241m=\u001b[39mscore_threshold,\n\u001b[0;32m    397\u001b[0m     append_payload\u001b[38;5;241m=\u001b[39mappend_payload,\n\u001b[0;32m    398\u001b[0m     consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m    399\u001b[0m     shard_key_selector\u001b[38;5;241m=\u001b[39mshard_key_selector,\n\u001b[0;32m    400\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    402\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py:563\u001b[0m, in \u001b[0;36mQdrantRemote.search\u001b[1;34m(self, collection_name, query_vector, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, append_payload, consistency, shard_key_selector, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(with_payload, grpc\u001b[38;5;241m.\u001b[39mWithPayloadSelector):\n\u001b[0;32m    561\u001b[0m     with_payload \u001b[38;5;241m=\u001b[39m GrpcToRest\u001b[38;5;241m.\u001b[39mconvert_with_payload_selector(with_payload)\n\u001b[1;32m--> 563\u001b[0m search_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp\u001b[38;5;241m.\u001b[39mpoints_api\u001b[38;5;241m.\u001b[39msearch_points(\n\u001b[0;32m    564\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    565\u001b[0m     consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m    566\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    567\u001b[0m     search_request\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSearchRequest(\n\u001b[0;32m    568\u001b[0m         vector\u001b[38;5;241m=\u001b[39mquery_vector,\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mquery_filter,\n\u001b[0;32m    570\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m    571\u001b[0m         offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    572\u001b[0m         params\u001b[38;5;241m=\u001b[39msearch_params,\n\u001b[0;32m    573\u001b[0m         with_vector\u001b[38;5;241m=\u001b[39mwith_vectors,\n\u001b[0;32m    574\u001b[0m         with_payload\u001b[38;5;241m=\u001b[39mwith_payload,\n\u001b[0;32m    575\u001b[0m         score_threshold\u001b[38;5;241m=\u001b[39mscore_threshold,\n\u001b[0;32m    576\u001b[0m         shard_key\u001b[38;5;241m=\u001b[39mshard_key_selector,\n\u001b[0;32m    577\u001b[0m     ),\n\u001b[0;32m    578\u001b[0m )\n\u001b[0;32m    579\u001b[0m result: Optional[List[types\u001b[38;5;241m.\u001b[39mScoredPoint]] \u001b[38;5;241m=\u001b[39m search_result\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch returned None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:1616\u001b[0m, in \u001b[0;36mSyncPointsApi.search_points\u001b[1;34m(self, collection_name, consistency, timeout, search_request)\u001b[0m\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_points\u001b[39m(\n\u001b[0;32m   1607\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1608\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1611\u001b[0m     search_request: m\u001b[38;5;241m.\u001b[39mSearchRequest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1612\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m m\u001b[38;5;241m.\u001b[39mInlineResponse20016:\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03m    Retrieve closest points based on vector similarity and given filtering conditions\u001b[39;00m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_for_search_points(\n\u001b[0;32m   1617\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m   1618\u001b[0m         consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m   1619\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1620\u001b[0m         search_request\u001b[38;5;241m=\u001b[39msearch_request,\n\u001b[0;32m   1621\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:750\u001b[0m, in \u001b[0;36m_PointsApi._build_for_search_points\u001b[1;34m(self, collection_name, consistency, timeout, search_request)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[0;32m    749\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    751\u001b[0m     type_\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mInlineResponse20016,\n\u001b[0;32m    752\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    753\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/collections/\u001b[39m\u001b[38;5;132;01m{collection_name}\u001b[39;00m\u001b[38;5;124m/points/search\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    754\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    755\u001b[0m     path_params\u001b[38;5;241m=\u001b[39mpath_params,\n\u001b[0;32m    756\u001b[0m     params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m    757\u001b[0m     content\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    758\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:79\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     78\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbuild_request(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, type_)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:96\u001b[0m, in \u001b[0;36mApiClient.send\u001b[1;34m(self, request, type_)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, type_: Type[T]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m---> 96\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiddleware(request, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_inner)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m201\u001b[39m, \u001b[38;5;241m202\u001b[39m]:\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:205\u001b[0m, in \u001b[0;36mBaseMiddleware.__call__\u001b[1;34m(self, request, call_next)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, call_next: Send) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_next(request)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:106\u001b[0m, in \u001b[0;36mApiClient.send_inner\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    226\u001b[0m     )\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.5, beta=0.5, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_stopwords.json\", stopwords_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid autoid with stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m lexical_pmid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      3\u001b[0m query_parser_stopwords \u001b[38;5;241m=\u001b[39m QueryProcessor(index_lexical\u001b[38;5;241m=\u001b[39mindex_name_lexical, lexical_pmid\u001b[38;5;241m=\u001b[39mlexical_pmid, index_name_semantic \u001b[38;5;241m=\u001b[39m coll_name_semantic, model\u001b[38;5;241m=\u001b[39m model, lexical_client\u001b[38;5;241m=\u001b[39mclient_lexical, semantic_client\u001b[38;5;241m=\u001b[39mclient_semantic, stopwords\u001b[38;5;241m=\u001b[39menglish_stopwords)\n\u001b[1;32m----> 4\u001b[0m evaluation(query_parser_stopwords, data, query_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m\"\u001b[39m,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval_results_BioASQ_all/hybrid_results_autoid_stopwords.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, stopwords_preprocessing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[28], line 41\u001b[0m, in \u001b[0;36mevaluation\u001b[1;34m(query_parser, data, query_type, alpha, beta, stopwords_preprocessing, path)\u001b[0m\n\u001b[0;32m     39\u001b[0m relevant_documents \u001b[38;5;241m=\u001b[39m clean_documents(question[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     40\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 41\u001b[0m results \u001b[38;5;241m=\u001b[39m query_parser\u001b[38;5;241m.\u001b[39mexecute_query(query,query_type \u001b[38;5;241m=\u001b[39m query_type, lex_parameter \u001b[38;5;241m=\u001b[39m alpha, semantic_parameter \u001b[38;5;241m=\u001b[39m beta,limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(relevant_documents), save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stopwords_preprocessing \u001b[38;5;241m=\u001b[39m stopwords_preprocessing)\n\u001b[0;32m     42\u001b[0m queries_time\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#results = [('20598273',1), ('4',1), ('6650562',1), ('2',1),('21995290',1),('15617541',1),('23001136',1),('8896569',1), ('12239580',1)]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 187\u001b[0m, in \u001b[0;36mQueryProcessor.execute_query\u001b[1;34m(self, query_str, query_type, lex_parameter, semantic_parameter, limit, save, stopwords_preprocessing)\u001b[0m\n\u001b[0;32m    184\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_query(query_str, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 187\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhybrid_query(text_query, query_str, lex_parameter, semantic_parameter, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid query type specified. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlexical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 154\u001b[0m, in \u001b[0;36mQueryProcessor.hybrid_query\u001b[1;34m(self, query_lexical, query_semantic, lex_parameter, semantic_parameter, limit)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncorrect parameters for Hybrid Queries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m lexical_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexical_query(query_lexical, limit \u001b[38;5;241m=\u001b[39m limit) \n\u001b[1;32m--> 154\u001b[0m semantic_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_query(query_semantic, limit)\n\u001b[0;32m    155\u001b[0m max_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    156\u001b[0m retrived_documents \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[23], line 125\u001b[0m, in \u001b[0;36mQueryProcessor.semantic_query\u001b[1;34m(self, query, limit)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model defined\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode(query)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    127\u001b[0m search_params\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSearchParams(\n\u001b[0;32m    128\u001b[0m     quantization\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mQuantizationSearchParams(rescore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescore)\n\u001b[0;32m    129\u001b[0m     )\n\u001b[0;32m    130\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_client\u001b[38;5;241m.\u001b[39msearch(collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_name_semantic,query_vector\u001b[38;5;241m=\u001b[39mquery_vector,search_params\u001b[38;5;241m=\u001b[39msearch_params, limit\u001b[38;5;241m=\u001b[39mlimit)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:517\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    514\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 517\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(features)\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    519\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:703\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    701\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    704\u001b[0m     x\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m    705\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    706\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    707\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    708\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    709\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    710\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:464\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    456\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    457\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    458\u001b[0m         hidden_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m         output_attentions,\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    465\u001b[0m         hidden_state,\n\u001b[0;32m    466\u001b[0m         attn_mask,\n\u001b[0;32m    467\u001b[0m         head_mask[i],\n\u001b[0;32m    468\u001b[0m         output_attentions,\n\u001b[0;32m    469\u001b[0m     )\n\u001b[0;32m    471\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:408\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    405\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_layer_norm(sa_output \u001b[38;5;241m+\u001b[39m x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    409\u001b[0m ffn_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer_norm(ffn_output \u001b[38;5;241m+\u001b[39m sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    411\u001b[0m output \u001b[38;5;241m=\u001b[39m (ffn_output,)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:343\u001b[0m, in \u001b[0;36mFFN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_chunking_to_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:239\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:346\u001b[0m, in \u001b[0;36mFFN.ff_chunk\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mff_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 346\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    347\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[0;32m    348\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Adela\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical\"\n",
    "lexical_pmid = False\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.5, beta=0.5, path = \"Eval_results_BioASQ_all/hybrid_results_autoid_stopwords.json\", stopwords_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with rescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.192\n",
      "Mean Average Precision = 0.403\n",
      "Mean Time needed to execute a query = 0.538\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.189\n",
      "Mean Average Precision = 0.389\n",
      "Mean Time needed to execute a query = 0.523\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.187\n",
      "Mean Average Precision = 0.378\n",
      "Mean Time needed to execute a query = 0.513\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.197\n",
      "Mean Average Precision = 0.392\n",
      "Mean Time needed to execute a query = 0.507\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.218\n",
      "Mean Average Precision = 0.405\n",
      "Mean Time needed to execute a query = 0.495\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.228\n",
      "Mean Average Precision = 0.403\n",
      "Mean Time needed to execute a query = 0.483\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.235\n",
      "Mean Average Precision = 0.400\n",
      "Mean Time needed to execute a query = 0.471\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.244\n",
      "Mean Average Precision = 0.406\n",
      "Mean Time needed to execute a query = 0.465\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.250\n",
      "Mean Average Precision = 0.409\n",
      "Mean Time needed to execute a query = 0.461\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.251\n",
      "Mean Average Precision = 0.409\n",
      "Mean Time needed to execute a query = 0.461\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.252\n",
      "Mean Average Precision = 0.410\n",
      "Mean Time needed to execute a query = 0.460\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.5, beta=0.5, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid 0.6 lexical and 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.6, beta=0.4, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore_06-04.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with alpha 0.7 and Beta 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.246\n",
      "Mean Average Precision = 0.412\n",
      "Mean Time needed to execute a query = 0.499\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.253\n",
      "Mean Average Precision = 0.406\n",
      "Mean Time needed to execute a query = 0.496\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.251\n",
      "Mean Average Precision = 0.397\n",
      "Mean Time needed to execute a query = 0.503\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.262\n",
      "Mean Average Precision = 0.408\n",
      "Mean Time needed to execute a query = 0.501\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.285\n",
      "Mean Average Precision = 0.424\n",
      "Mean Time needed to execute a query = 0.490\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.291\n",
      "Mean Average Precision = 0.420\n",
      "Mean Time needed to execute a query = 0.478\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.296\n",
      "Mean Average Precision = 0.418\n",
      "Mean Time needed to execute a query = 0.466\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.303\n",
      "Mean Average Precision = 0.422\n",
      "Mean Time needed to execute a query = 0.463\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.308\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.462\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.307\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.469\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.308\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.469\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.7, beta=0.3, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore_07-03.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.8 and 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.246\n",
      "Mean Average Precision = 0.413\n",
      "Mean Time needed to execute a query = 0.522\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.253\n",
      "Mean Average Precision = 0.406\n",
      "Mean Time needed to execute a query = 0.526\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.251\n",
      "Mean Average Precision = 0.398\n",
      "Mean Time needed to execute a query = 0.537\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.262\n",
      "Mean Average Precision = 0.409\n",
      "Mean Time needed to execute a query = 0.527\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.285\n",
      "Mean Average Precision = 0.424\n",
      "Mean Time needed to execute a query = 0.511\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.292\n",
      "Mean Average Precision = 0.420\n",
      "Mean Time needed to execute a query = 0.496\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.296\n",
      "Mean Average Precision = 0.418\n",
      "Mean Time needed to execute a query = 0.481\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.303\n",
      "Mean Average Precision = 0.423\n",
      "Mean Time needed to execute a query = 0.476\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.308\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.473\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.307\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.475\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.308\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.475\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.8, beta=0.2, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore_08-02.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.9 lexical and 0.1 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.246\n",
      "Mean Average Precision = 0.413\n",
      "Mean Time needed to execute a query = 0.515\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.253\n",
      "Mean Average Precision = 0.406\n",
      "Mean Time needed to execute a query = 0.528\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.251\n",
      "Mean Average Precision = 0.398\n",
      "Mean Time needed to execute a query = 0.532\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.262\n",
      "Mean Average Precision = 0.409\n",
      "Mean Time needed to execute a query = 0.532\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.285\n",
      "Mean Average Precision = 0.424\n",
      "Mean Time needed to execute a query = 0.525\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.292\n",
      "Mean Average Precision = 0.420\n",
      "Mean Time needed to execute a query = 0.514\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.296\n",
      "Mean Average Precision = 0.418\n",
      "Mean Time needed to execute a query = 0.500\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.303\n",
      "Mean Average Precision = 0.423\n",
      "Mean Time needed to execute a query = 0.491\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.308\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.486\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.307\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.485\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.308\n",
      "Mean Average Precision = 0.425\n",
      "Mean Time needed to execute a query = 0.484\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.8, beta=0.2, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore_09-01.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.4 lexical and 0.6 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.186\n",
      "Mean Average Precision = 0.327\n",
      "Mean Time needed to execute a query = 0.533\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.183\n",
      "Mean Average Precision = 0.315\n",
      "Mean Time needed to execute a query = 0.546\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.182\n",
      "Mean Average Precision = 0.310\n",
      "Mean Time needed to execute a query = 0.546\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.192\n",
      "Mean Average Precision = 0.321\n",
      "Mean Time needed to execute a query = 0.550\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.212\n",
      "Mean Average Precision = 0.330\n",
      "Mean Time needed to execute a query = 0.542\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.222\n",
      "Mean Average Precision = 0.328\n",
      "Mean Time needed to execute a query = 0.528\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.229\n",
      "Mean Average Precision = 0.324\n",
      "Mean Time needed to execute a query = 0.512\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.239\n",
      "Mean Average Precision = 0.327\n",
      "Mean Time needed to execute a query = 0.505\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.245\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.503\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.246\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.504\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.247\n",
      "Mean Average Precision = 0.326\n",
      "Mean Time needed to execute a query = 0.504\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.4, beta=0.6, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore_04-06.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.3 lexical and 0.7 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.186\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.511\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.183\n",
      "Mean Average Precision = 0.314\n",
      "Mean Time needed to execute a query = 0.509\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.182\n",
      "Mean Average Precision = 0.309\n",
      "Mean Time needed to execute a query = 0.517\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.192\n",
      "Mean Average Precision = 0.320\n",
      "Mean Time needed to execute a query = 0.518\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.212\n",
      "Mean Average Precision = 0.329\n",
      "Mean Time needed to execute a query = 0.505\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.222\n",
      "Mean Average Precision = 0.328\n",
      "Mean Time needed to execute a query = 0.491\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.229\n",
      "Mean Average Precision = 0.323\n",
      "Mean Time needed to execute a query = 0.480\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.239\n",
      "Mean Average Precision = 0.326\n",
      "Mean Time needed to execute a query = 0.474\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.245\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.470\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.246\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.471\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.247\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.471\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.3, beta=0.7, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore_03-07.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.2 lexical and 0.8 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.186\n",
      "Mean Average Precision = 0.327\n",
      "Mean Time needed to execute a query = 0.518\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.183\n",
      "Mean Average Precision = 0.314\n",
      "Mean Time needed to execute a query = 0.515\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.182\n",
      "Mean Average Precision = 0.310\n",
      "Mean Time needed to execute a query = 0.512\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.192\n",
      "Mean Average Precision = 0.320\n",
      "Mean Time needed to execute a query = 0.510\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.212\n",
      "Mean Average Precision = 0.329\n",
      "Mean Time needed to execute a query = 0.499\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.222\n",
      "Mean Average Precision = 0.328\n",
      "Mean Time needed to execute a query = 0.486\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.229\n",
      "Mean Average Precision = 0.323\n",
      "Mean Time needed to execute a query = 0.473\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.239\n",
      "Mean Average Precision = 0.326\n",
      "Mean Time needed to execute a query = 0.467\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.245\n",
      "Mean Average Precision = 0.324\n",
      "Mean Time needed to execute a query = 0.464\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.246\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.466\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.247\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.466\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.2, beta=0.8, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore_02-08.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Hybrid with 0.1 lexical and 0.9 semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.186\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.509\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.183\n",
      "Mean Average Precision = 0.313\n",
      "Mean Time needed to execute a query = 0.506\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.182\n",
      "Mean Average Precision = 0.311\n",
      "Mean Time needed to execute a query = 0.507\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.192\n",
      "Mean Average Precision = 0.320\n",
      "Mean Time needed to execute a query = 0.510\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.212\n",
      "Mean Average Precision = 0.330\n",
      "Mean Time needed to execute a query = 0.499\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.222\n",
      "Mean Average Precision = 0.328\n",
      "Mean Time needed to execute a query = 0.485\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.229\n",
      "Mean Average Precision = 0.323\n",
      "Mean Time needed to execute a query = 0.473\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.239\n",
      "Mean Average Precision = 0.326\n",
      "Mean Time needed to execute a query = 0.467\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.245\n",
      "Mean Average Precision = 0.324\n",
      "Mean Time needed to execute a query = 0.464\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.246\n",
      "Mean Average Precision = 0.324\n",
      "Mean Time needed to execute a query = 0.464\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.247\n",
      "Mean Average Precision = 0.325\n",
      "Mean Time needed to execute a query = 0.464\n"
     ]
    }
   ],
   "source": [
    "index_name_lexical = \"medline-faiss-hnsw-lexical-pmid\"\n",
    "lexical_pmid = True\n",
    "query_parser_stopwords = QueryProcessor(index_lexical=index_name_lexical, lexical_pmid=lexical_pmid, index_name_semantic = coll_name_semantic, model= model, lexical_client=client_lexical, semantic_client=client_semantic, stopwords=english_stopwords)\n",
    "query_parser_stopwords.set_rescore(True)\n",
    "evaluation(query_parser_stopwords, data, query_type=\"hybrid\",alpha=0.1, beta=0.9, path = \"Eval_results_BioASQ_all/hybrid_results_pmid_recore_01-09.json\", stopwords_preprocessing=True)\n",
    "query_parser_stopwords.set_rescore(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation based on PubMed website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id list =  ['11076767', '38284126', '15094110', '30388611', '38837578', '12666201', '30661986', '22242013', '36997062', '22937083']\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "# Always tell NCBI who you are (your email address)\n",
    "Entrez.email = \"lcassano00@gmail.com\"\n",
    "def search_pubmed(query, limit = 10, mesh=True):\n",
    "    if not mesh:\n",
    "        query += \"[Title/Abstract]\"\n",
    "    # Use Entrez.esearch to search for articles matching the query in PubMed\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=limit, sort=\"relevance\",)\n",
    "    \n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    # Get the list of Ids returned by the search\n",
    "    id_list = record[\"IdList\"]\n",
    "    return id_list\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    # Use Entrez.efetch to get the article details from the list of Ids\n",
    "    ids = ','.join(id_list)\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=ids, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return records\n",
    "# Example usage\n",
    "\n",
    "query = \"Is the protein Papilin secreted?\"\n",
    "id_list = search_pubmed(query)\n",
    "print(\"Id list = \",id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id list =  ['11076767', '38284126', '15094122', '21784067', '7515725']\n"
     ]
    }
   ],
   "source": [
    "query = \"Is the protein Papilin secreted?\"\n",
    "id_list = search_pubmed(query, mesh=False)\n",
    "print(\"Id list = \",id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(retrived_doc, true_doc):\n",
    "    # Initialize variables\n",
    "    precision_sum = 0\n",
    "    num_retrieved_docs = 0\n",
    "    \n",
    "    # Calculate precision at each relevant document position\n",
    "    for i, retrived in enumerate(retrived_doc, start=1):\n",
    "        pmid = retrived  # CHAGEd from pmid, _ = retrived to pmid = retrived (CAUSED PROBLEM IN EVALUATION ON PUBMEDSEARCH)\n",
    "        if pmid in true_doc:  # Check if the document is relevant\n",
    "            num_retrieved_docs += 1\n",
    "            precision_sum += num_retrieved_docs / i  # Calculate precision at cutoff i\n",
    "\n",
    "    # Calculate average precision\n",
    "    if num_retrieved_docs == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return precision_sum / num_retrieved_docs\n",
    "def evaluation_pubmed(query_type, data,mesh=True,path = \"query_result.json\"):\n",
    "    avg_precisions_sum = [] # sum all average precision and divide with number of queries \n",
    "    precisions_sum = []\n",
    "    queries_time = []\n",
    "    for i,question in enumerate(data['questions']):\n",
    "        dict_to_save = {}\n",
    "        query = question['body']\n",
    "        dict_to_save['query'] = query\n",
    "        dict_to_save['query_type'] = query_type\n",
    "        relevant_documents = clean_documents(question['documents'])\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = search_pubmed(query, limit = len(relevant_documents),mesh=mesh)\n",
    "        queries_time.append(time.time() - start_time)\n",
    "        \n",
    "        dict_to_save['true_documents'] = relevant_documents\n",
    "        dict_to_save['retrieved_documents'] = results\n",
    "       \n",
    "        number_retrieved_documents = 0\n",
    "        for pmid in results:\n",
    "            if pmid in relevant_documents:\n",
    "                number_retrieved_documents +=1\n",
    "\n",
    "        precision = number_retrieved_documents / len(relevant_documents)\n",
    "        recall = number_retrieved_documents / len(relevant_documents)\n",
    "        avg_precision = average_precision(results, relevant_documents)\n",
    "       \n",
    "        precisions_sum.append(precision)\n",
    "        #recalls.append(recall)\n",
    "        \n",
    "        avg_precisions_sum.append(avg_precision)\n",
    "        \n",
    "        dict_to_save['precision'] = precision\n",
    "        #dict_to_save['recall'] = recall\n",
    "        dict_to_save['avg_precision'] = avg_precision\n",
    "        with open(path, 'a') as output_file:\n",
    "            output_file.write(json.dumps(dict_to_save) + '\\n')\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f\"Analyzed {i+1} queries\")\n",
    "            print(\"Actual Results...\")\n",
    "            print(f\"Mean precision = {np.mean(precisions_sum):.3f}\")\n",
    "            #print(f\"Mean recall = {np.mean(recalls):.3f}\")\n",
    "            print(f\"Mean Average Precision = {np.mean(avg_precisions_sum):.3f}\")\n",
    "            print(f\"Mean Time needed to execute a query = {np.mean(queries_time):.3f}\")\n",
    "    print(\"FINAL RESULTS \")\n",
    "    print(f\"Mean precision = {np.mean(precisions_sum):.3f}\")\n",
    "    #print(f\"Mean recall = {np.mean(recalls):.3f}\")\n",
    "    print(f\"Mean Average Precision = {np.mean(avg_precisions_sum):.3f}\")\n",
    "    print(f\"Mean Time needed to execute a query = {np.mean(queries_time):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pubmed with Mesh Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mesh terms are applied automatically by PubMed website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.090\n",
      "Mean Average Precision = 0.177\n",
      "Mean Time needed to execute a query = 1.299\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.088\n",
      "Mean Average Precision = 0.176\n",
      "Mean Time needed to execute a query = 1.316\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.087\n",
      "Mean Average Precision = 0.167\n",
      "Mean Time needed to execute a query = 1.322\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.095\n",
      "Mean Average Precision = 0.176\n",
      "Mean Time needed to execute a query = 1.292\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.110\n",
      "Mean Average Precision = 0.191\n",
      "Mean Time needed to execute a query = 1.258\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.111\n",
      "Mean Average Precision = 0.186\n",
      "Mean Time needed to execute a query = 1.238\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.110\n",
      "Mean Average Precision = 0.181\n",
      "Mean Time needed to execute a query = 1.224\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.112\n",
      "Mean Average Precision = 0.182\n",
      "Mean Time needed to execute a query = 1.215\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.117\n",
      "Mean Average Precision = 0.187\n",
      "Mean Time needed to execute a query = 1.205\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.119\n",
      "Mean Average Precision = 0.192\n",
      "Mean Time needed to execute a query = 1.204\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.119\n",
      "Mean Average Precision = 0.192\n",
      "Mean Time needed to execute a query = 1.204\n"
     ]
    }
   ],
   "source": [
    "evaluation_pubmed(data=data, query_type=\"PubMed website\", path=\"Eval_results_BioASQ_all/Pubmed_mesh.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation PubMed without mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.059\n",
      "Mean Average Precision = 0.130\n",
      "Mean Time needed to execute a query = 1.119\n",
      "Analyzed 1000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.059\n",
      "Mean Average Precision = 0.132\n",
      "Mean Time needed to execute a query = 1.130\n",
      "Analyzed 1500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.056\n",
      "Mean Average Precision = 0.125\n",
      "Mean Time needed to execute a query = 1.139\n",
      "Analyzed 2000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.069\n",
      "Mean Average Precision = 0.138\n",
      "Mean Time needed to execute a query = 1.145\n",
      "Analyzed 2500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.082\n",
      "Mean Average Precision = 0.153\n",
      "Mean Time needed to execute a query = 1.148\n",
      "Analyzed 3000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.083\n",
      "Mean Average Precision = 0.149\n",
      "Mean Time needed to execute a query = 1.152\n",
      "Analyzed 3500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.085\n",
      "Mean Average Precision = 0.147\n",
      "Mean Time needed to execute a query = 1.152\n",
      "Analyzed 4000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.086\n",
      "Mean Average Precision = 0.147\n",
      "Mean Time needed to execute a query = 1.152\n",
      "Analyzed 4500 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.091\n",
      "Mean Average Precision = 0.152\n",
      "Mean Time needed to execute a query = 1.145\n",
      "Analyzed 5000 queries\n",
      "Actual Results...\n",
      "Mean precision = 0.092\n",
      "Mean Average Precision = 0.154\n",
      "Mean Time needed to execute a query = 1.143\n",
      "FINAL RESULTS \n",
      "Mean precision = 0.092\n",
      "Mean Average Precision = 0.154\n",
      "Mean Time needed to execute a query = 1.143\n"
     ]
    }
   ],
   "source": [
    "evaluation_pubmed(data=data, query_type=\"PubMed website no mash\", mesh = False, path=\"Eval_results_BioASQ_all/Pubmed_no_mesh.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
